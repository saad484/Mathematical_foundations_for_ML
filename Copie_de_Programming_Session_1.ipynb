{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saad484/Mathematical_foundations_for_ML/blob/main/Copie_de_Programming_Session_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A84sSMXE3hbZ"
      },
      "source": [
        "# <center> Mathematical Foundations for ML</center>\n",
        "\n",
        "## <center>Programming Session 1 - Applications of Matrix Factorization for Word Embedding -"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Presentation of the Programming Session:\n"
      ],
      "metadata": {
        "id": "i3UNZ1BIqRBM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNbuq3vZIg-Q"
      },
      "source": [
        "\n",
        "\n",
        "In this programming session, we would like to implement the GloVe approach. It was introduced by Jeffrey Pennington, Richard Socher and  Christopher D. Manning in the paper: [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)\n",
        "\n",
        "The programming session is subdivided into three parts:\n",
        "\n",
        "* In section 1, the objective is to load the data, preprocess it and create the **co-occurence matrix**.\n",
        "* In section 2, the objective is to train the model by using two different methods: **Gradient Descent** and **Alternating Least Squares**.\n",
        "* In section 3, the objective is to add a penalty term to the loss function as a **regularization** technique.\n",
        "\n",
        "**Notations:**\n",
        "\n",
        "* $\\mathcal{M}_{n,p}(\\mathbb{R})$ is the space of the matrices composed of n rows and p columns.\n",
        "\n",
        "* $I_n \\in \\mathcal{M}_{n,n}(\\mathbb{R})$ is the identity matrix of size n.\n",
        "\n",
        "* For all $z \\in \\mathbb{R}^D$, the $\\mathcal{L}^2$ norm on $\\mathbb{R}^D$ of $z$ is defined as follows: $||z||_2^2 = z^T z$\n",
        "\n",
        "*  For all $A = [a_{ij}]_{i,j} \\in \\mathcal{M}_{n,p}(\\mathbb{R})$ we define the Frobenius norm of $A$ as follows: $||A||_{\\text{F}}^2 = \\sum\\limits_{i=1}^n \\sum\\limits_{j=1}^p a_{ij}^2$\n",
        "\n",
        "* The gradient of a function $f : \\theta \\in \\mathbb{R}^D \\mapsto \\mathbb{R}$ at $\\theta\\in \\mathbb{R}^D$ is denoted as follows $\\nabla_{\\theta}f(\\theta) = \\left(\\frac{\\partial f}{\\partial \\theta_1}(\\theta), \\dots, \\frac{\\partial f}{\\partial \\theta_D}(\\theta) \\right)$\n",
        "\n",
        "**Convention:**\n",
        "\n",
        "* The rows $(A_i)_{1 \\leq i \\leq n }$ of a matrix $A = \\begin{pmatrix}\n",
        "- & A_1 & - \\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "- & A_n & -\n",
        "\\end{pmatrix}\\in \\mathcal{M}_{n,p}(\\mathbb{R}) $ are \t\t\t\tconsidered $\\mathcal{M}_{p,1}(\\mathbb{R})$ matrices.\n",
        "\n",
        "* The columns $(B_j)_{1 \\leq j \\leq p }$ of a matrix $B = \\begin{pmatrix}\n",
        "| & \\dots & | \\\\\n",
        "B_1 & \\dots & B_p \\\\\n",
        "| & \\dots & |\n",
        "\\end{pmatrix}\\in \\mathcal{M}_{n,p}(\\mathbb{R}) $ are considered $\\mathcal{M}_{n,1}(\\mathbb{R})$ matrices.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCcWOvm03Zxu"
      },
      "source": [
        "# Import basic libraries\n",
        "import pandas as pd # for dataframes\n",
        "import numpy as np # for arrays\n",
        "import matplotlib.pyplot as plt # for plots\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # for processing text\n",
        "import random # to shuffle the sequences\n",
        "import os\n",
        "plt.style.use('dark_background') # to adapt the colors to a dark background\n",
        "from IPython.display import Image # for showing graphs from the lectures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yDVjd7FbF9L"
      },
      "source": [
        "# Hyperparameters\n",
        "MAX_VOCAB = 999\n",
        "C = 10 # Context size\n",
        "V = MAX_VOCAB + 1 # Vocabulary size\n",
        "EPOCHS = 64\n",
        "D = 100 # Embedding dimension"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEg4IWrPY6QE"
      },
      "source": [
        "# 1. Getting the statistics of the word occurences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_myLbIjnJQx4"
      },
      "source": [
        "## 1.1 Introducing the problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pf_Enu1KgPy"
      },
      "source": [
        "The objective of the programming session is to train a model on a corpus of training sentences in order to represent words in a $D$-dimensional space. We would like to encode the similarity between the words in the embedding vectors themselves."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SutTRTQJT4J"
      },
      "source": [
        "\n",
        "---\n",
        "<font color=green>Q1:</font>\n",
        "<br><font color='green'>\n",
        "Explain why this notion of similarity is not encoded in the one hot vector representation of words.\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDVPk01tOsfT"
      },
      "source": [
        "---\n",
        "**Solution**:\n",
        "\n",
        "Like explained in Slide 7 of [Lecture 5](https://hm-ai.github.io/MLF/Lectures/Lecture_5.pdf), any two V-dimensional one hot vectors will be orthogonal according to the dot product similarty measure.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmoXLYiyKlfr"
      },
      "source": [
        "Several methods have been used to create word embeddings. The most popular ones rely on the intuition that *a word's meaning is given by the words that frequently appear close-by*.\n",
        "\n",
        "For instance, [the word2vec approach](https://arxiv.org/pdf/1301.3781.pdf) represents the tokens as parameters of a shallow neural network predicting a word's context given the world itself.\n",
        "\n",
        "Although the shallow window-based model captures linguistic patterns between word vectors and performs well on the word analogy task ($w_{\\text{France}} - w_{\\text{Paris}} \\approx w_{\\text{England}} - w_{\\text{London}}$), the model suffers from the disadvantage that they do not operate directly and the co-occurence statistics.\n",
        "\n",
        "The GloVe method is a popular method used to learn low-dimensional word representations by using **matrix factorization** methods on a matrix of word-word **co-occurence** statistics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn9LBGBIj9K6"
      },
      "source": [
        "## 1.2 Preprocessing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG-5uQsmTf9L"
      },
      "source": [
        "The **data** folder contains a csv file named `RedditNews.csv` (Source: Sun, J. (2016, August) Daily News for Stock Market Prediction, Version 1. Retrieved [26 may 2020]).\n",
        "\n",
        "In the `RedditNews.csv` file are stored historical news headlines from Reddit WorldNews Channel, ranked by reddit users' votes, and only the top 25 headlines are considered for a single date.\n",
        "\n",
        "You will find two colomns:\n",
        "\n",
        "\n",
        "* The first column is for the \"date\".\n",
        "* The second column is for the \"News\". As all the news are ranked from top to bottom, there are only 25 lines for each date.  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q2:</font>\n",
        "<br><font color='green'>\n",
        "Load the data from the csv file, create a list of all the news.\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "k6wCO8hAF3Vo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-JxcrF8Khhs"
      },
      "source": [
        "# Import the data\n",
        "url='https://drive.google.com/uc?id=1ITAmVLaBiR9XI3jc81U4M2Cn1SRhw8mM'\n",
        "data = pd.read_csv(url)\n",
        "# Select the news\n",
        "news = data[\"News\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IhGBiEn-BOTy",
        "outputId": "b9f28559-776a-4f5c-d640-4eb419a79a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date                                               News\n",
              "0  2016-07-01  A 117-year-old woman in Mexico City finally re...\n",
              "1  2016-07-01   IMF chief backs Athens as permanent Olympic host\n",
              "2  2016-07-01  The president of France says if Brexit won, so...\n",
              "3  2016-07-01  British Man Who Must Give Police 24 Hours' Not...\n",
              "4  2016-07-01  100+ Nobel laureates urge Greenpeace to stop o..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cd6a7c1-7c98-41f2-af60-3182f1380667\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>A 117-year-old woman in Mexico City finally re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>IMF chief backs Athens as permanent Olympic host</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>The president of France says if Brexit won, so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>British Man Who Must Give Police 24 Hours' Not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>100+ Nobel laureates urge Greenpeace to stop o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cd6a7c1-7c98-41f2-af60-3182f1380667')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cd6a7c1-7c98-41f2-af60-3182f1380667 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cd6a7c1-7c98-41f2-af60-3182f1380667');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d58d9e96-eec5-435d-a41b-942ebf0c8af5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d58d9e96-eec5-435d-a41b-942ebf0c8af5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d58d9e96-eec5-435d-a41b-942ebf0c8af5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 73608,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2943,\n        \"samples\": [\n          \"2014-03-13\",\n          \"2013-08-28\",\n          \"2009-12-04\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"News\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 73537,\n        \"samples\": [\n          \"Tens of thousands fill Rabin Square in Israel for anti-Netanyahu rally\",\n          \"b'Third in a series of of pipline explosions hits BC, Canada'\",\n          \"Man sentenced to death in Saudi Arabia will be crucified\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSiWG1LOTH8-"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "<font color=green>Q3:</font>\n",
        "<br><font color='green'>\n",
        "Preprocess the data by transforming the list of sentences into a list of sequences of integers called `news_processed` , via a dictionary that maps the words to integers.\n",
        "</font>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<center><img width=\"400\" src = \"https://drive.google.com/uc?export=view&id=15_ocFu9iG0sOPmK0dKhECzTUbIXFSeHC\"></center>"
      ],
      "metadata": {
        "id": "s5grXRA_CgxV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qACCC4u1LHau"
      },
      "source": [
        "# Preprocessing\n",
        "tokenizer = Tokenizer(num_words = MAX_VOCAB,\n",
        "                      oov_token='UNK',\n",
        "                      filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                      lower=True)\n",
        "# Create the word_index dictionary\n",
        "tokenizer.fit_on_texts(news)\n",
        "# Transforming news into a list of lists of integers\n",
        "news_processed = tokenizer.texts_to_sequences(news)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q4:</font>\n",
        "<br><font color='green'>\n",
        "For each sentence, add a specific index for the token \"$<\\text{sos}>$\" (start of sequence) at the beginning of each sequence and an index for the token \"$<\\text{eos}>$\" (end of sequence) at the end of each sequence. The resulting list of lists of integers is called `sequences`.\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "gsuspkmgDvd3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UUGI0oNLWRk"
      },
      "source": [
        "# Introduce the tokens \"<sos>\" and \"<eos>\":\n",
        "word_index = {}\n",
        "word_index['<sos>'] = 0\n",
        "for k, v in tokenizer.word_index.items():\n",
        "    if v < MAX_VOCAB:\n",
        "        word_index[k] = v\n",
        "word_index['<eos>'] = MAX_VOCAB\n",
        "\n",
        "# Shuffle the sentences\n",
        "random.shuffle(news_processed)\n",
        "\n",
        "# add the indices of <sos> and <eos>\n",
        "sequences = []\n",
        "for sequence in news_processed:\n",
        "    sequences.append([0] + sequence + [MAX_VOCAB])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37bxb3akkE4B"
      },
      "source": [
        "## 1.3 Creating the co-occurence matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMXi6HniTk6j"
      },
      "source": [
        "Let $V$ be the vocabulary size of the training corpus.\n",
        "\n",
        "In [Lecture 5](https://hm-ai.github.io/MLF/Lectures/Lecture_5.pdf), we have defined the co-occurence matrix $X = [X_{ij}]_{i,j} \\in \\mathcal{M}_{V,V}(\\mathbb{R})$, whose entries $X_{ij}$ represent the number of times word $j$ appears in the context of word $i$.\n",
        "\n",
        "Algorithm 1 summarizes the steps involved in estimating the co-occurence matrix from the corpus `sequences`.\n",
        "\n",
        "<center><img width=\"400\" src = \"https://drive.google.com/uc?export=view&id=186c4b_X8mDEgBoVNZKEw7sfXOzKa-KN-\"></center>\n",
        "\n",
        "\n",
        "In Algorithm 1, each time a word $w[j]$ (of index $j$ in sequence) appears in the context of a center word $w[i]$ (of index $i$ in sequence), we increase the value of $X[w[i], w[j]]$ by a value of $1$ regardless of how close the word $w[j]$ is to the word $w[i]$.\n",
        "\n",
        "We would like to take into consideration the distance $d(i,j)$ between the center word $w[i]$ and the context word $w[j]$ when updating the value $X[w[i], w[j]]$, as shown the following figure:\n",
        "\n",
        "<center><img width=\"600\" src = \"https://drive.google.com/uc?export=view&id=1m1_32ovMfjkRVb-B_3gPizDI1QUfZjQ4\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q5:</font>\n",
        "<br><font color='green'>\n",
        "Explain why it makes more sense to use the following update equation for $X[w[i], w[j]]$ when word $w[j]$ of index $j$ is in the context word $w[i]$ of index $i$.\n",
        "\n",
        "\\begin{equation*}\n",
        "X[w[i], w[j]] \\longleftarrow X[w[i], w[j]] + \\frac{1}{|i-j|}\n",
        "\\end{equation*}\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "e1M45t0GD0xC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVnkACgmLcub"
      },
      "source": [
        "---\n",
        "**Solution**\n",
        "\n",
        "* By using the update: $X[w[i], w[j]] \\longleftarrow X[w[i], w[j]] + 1$ we make the assumption that all the words $w[j]$ are equally important as context vectors of center word $w[i]$\n",
        "\n",
        "* By using the update: $X[w[i], w[j]] \\longleftarrow X[w[i], w[j]] + \\frac{1}{|i-j|}$, we would like to give more weight to closer context words because they are more related to the center word.\n",
        "\n",
        "* Another benefit from the update $X[w[i], w[j]] \\longleftarrow X[w[i], w[j]] + \\frac{1}{|i-j|}$ is to reduce the impact of the `context_size` hyperparameter.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q6:</font>\n",
        "<br><font color='green'>\n",
        "Implement Algorithm 2 to get the co-occurence matrix $X$ using a function called `get_cooccurence_matrix()`.\n",
        "\n",
        "The function takes as arguments `sequences`, `context_size` and `vocabulary_size` and outputs the matrix `X`.\n",
        "</font>\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<center><img width=\"400\" src = \"https://drive.google.com/uc?export=view&id=1Xt6SXVNxlsPHqIWk1IIaLOZcpTrQWZSd\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "XI-bKFPhD2Bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_occurence_matrix(sentences, context_size, vocabulary_size):\n",
        "  \"\"\"\n",
        "  This functions aims at creating the co-occurence matrix from the corpus\n",
        "  composed of sentences\n",
        "  \"\"\"\n",
        "  X = np.zeros((vocabulary_size, vocabulary_size))\n",
        "  N = len(sentences)\n",
        "  print(\"number of sentences to process:\", N)\n",
        "  it = 0\n",
        "  for sentence in sentences:\n",
        "      it += 1\n",
        "      if it % 10000 == 0:\n",
        "          print(\"processed\", it, \"/\", N)\n",
        "      n = len(sentence)\n",
        "      for i in range(n):\n",
        "          # center word\n",
        "          w_i = sentence[i]\n",
        "\n",
        "          start = max(0, i - context_size)\n",
        "          end = min(n-1, i + context_size)\n",
        "\n",
        "          # we can either choose only one side as context, or both\n",
        "          # here we are doing both\n",
        "\n",
        "          # left context side\n",
        "          for j in range(start, i):\n",
        "              # context word\n",
        "              w_j = sentence[j]\n",
        "              # inverse of distance between w_i and w_j\n",
        "              inverse_distance = 1. / (i-j)\n",
        "              # Add the inverse of the distance to X[w_i, w_j]\n",
        "              X[w_i, w_j] += inverse_distance\n",
        "\n",
        "          # right context side\n",
        "          for j in range(i+1, end+1):\n",
        "              # context word\n",
        "              w_j = sentence[j]\n",
        "              # inverse of distance between w_i and w_j\n",
        "              inverse_distance = 1. / (j-i)\n",
        "              # Add the inverse of the distance to X[w_i, w_j]\n",
        "              X[w_i, w_j] += inverse_distance\n",
        "  return X"
      ],
      "metadata": {
        "id": "Hlpk4oBmHfNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcufa32cNtgM",
        "outputId": "11b63d29-8cd4-42a8-b70e-68d20b8b661d"
      },
      "source": [
        "print(\"Get the co-occurence matrix X...\")\n",
        "X = get_occurence_matrix(sequences, C, V)\n",
        "print(\"The shape of X is\", X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get the co-occurence matrix X...\n",
            "number of sentences to process: 73608\n",
            "processed 10000 / 73608\n",
            "processed 20000 / 73608\n",
            "processed 30000 / 73608\n",
            "processed 40000 / 73608\n",
            "processed 50000 / 73608\n",
            "processed 60000 / 73608\n",
            "processed 70000 / 73608\n",
            "The shape of X is (1000, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zM372IuTZlr"
      },
      "source": [
        "\n",
        "\n",
        "Since non-zero values in the matrix $X$ are very large, we apply the logarithm function to all the elements of $X$ (after adding 1 to all the entries $X_{ij}$ to avoid applying the logarithm on zero values). The resulting matrix is still a sparse matrix. We will denote it $\\log X$.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q7:</font>\n",
        "<br><font color='green'>\n",
        "Create the matrix $\\log X$, call it `logX`.\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "U4c7UN5CD3ba"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8ANrmOAOEb8",
        "outputId": "99a58c3b-3277-4aa7-8cfc-1a0887d2dcd5"
      },
      "source": [
        "print(\"Get logX...\")\n",
        "logX = np.log(X+1)\n",
        "print(\"The shape of logX is\", logX.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get logX...\n",
            "The shape of logX is (1000, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNTHnF-LkFFK"
      },
      "source": [
        "# 2. Training the weighted least squares regression model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHIrgh9bkFM-"
      },
      "source": [
        "## 2.1 Introducing the cost function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r59PLdpZkFXS"
      },
      "source": [
        "The logarithm of the co-occurence matrix $\\log X$ has been defined in the previous section. The objective of this section is to approximate $\\log X$ using a factorization method as follows:\n",
        "\n",
        "\\begin{equation*}\n",
        "\t\\forall (i,j) \\in \\{1, \\dots, V \\}^2 \\quad \\log X_{ij} \\approx W_i^T \\tilde{W}_j + b_i + \\tilde{b}_j\n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "The parameters of the regression model are:\n",
        "\n",
        "\n",
        "* A first **embedding matrix** and a bias term associated with it:\n",
        "\t\\begin{equation*}\n",
        "W = \\begin{pmatrix}\n",
        "- & W_1 & - \\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "- & W_V & -\n",
        "\\end{pmatrix}\\in \\mathcal{M}_{V, D}(\\mathbb{R}), \t\\quad  \tb = \\begin{pmatrix}\n",
        " b_1  \\\\\n",
        " \\vdots  \\\\\n",
        " b_V  \n",
        "\\end{pmatrix}\\in \\mathbb{R}^{V}\n",
        "\t\\end{equation*}\n",
        "\n",
        "\n",
        "* A second **embedding matrix** and a bias term associated with it:\n",
        "\t\\begin{equation*}\n",
        "\\tilde{W} = \\begin{pmatrix}\n",
        "- & \\tilde{W}_1 & - \\\\\n",
        "\\vdots & \\vdots & \\vdots \\\\\n",
        "- & \\tilde{W}_V & -\n",
        "\\end{pmatrix}\\in \\mathcal{M}_{V, D}(\\mathbb{R}), \\quad \\tilde{b} = \\begin{pmatrix}\n",
        " \\tilde{b}_1  \\\\\n",
        " \\vdots  \\\\\n",
        " \\tilde{b}_V  \n",
        "\\end{pmatrix}\\in \\mathbb{R}^{V}\n",
        "\t\\end{equation*}\n",
        "\n",
        "\n",
        "Instead of equal-weighting all the co-occurences, we introduce a **weighting function** $f(X_{ij})$ defined as follows:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\forall x \\in \\mathbb{R}_{+} \\quad f(x) =  \\begin{cases}\n",
        "      (x/x_{\\text{max}})^{\\alpha} & \\text{if   $x < x_{\\text{max}}$}\\\\\n",
        "      1 & \\text{otherwise}\n",
        "          \\end{cases}  \n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "The function $f$ is represented in the following figure with $x_{\\text{max}}=100$ and $\\alpha=0.75$\n",
        "\n",
        "<center><img width=\"400\" src = \"https://drive.google.com/uc?export=view&id=1D7muXkREj-5pPVUWyAfe8qrwYeIe0XzN\"></center>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q8:</font>\n",
        "<br><font color='green'>\n",
        "Create a matrix of shape $(V, V)$ whose entries are $f(X_{ij})$.\n",
        "Let's call it `fX`. Use the hyperparameters $x_{\\text{max}}=100$ and $\\alpha=0.75$\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "dBlWZ8ZsD4qx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEnJbfO6ObLg",
        "outputId": "cfe0833c-f59e-4719-ad4f-97c557305bd8"
      },
      "source": [
        "print(\"Get f(X)...\")\n",
        "xmax = 100\n",
        "alpha = 0.75\n",
        "fX = np.zeros((V, V))\n",
        "fX[X < xmax] = (X[X < xmax] / float(xmax)) ** alpha\n",
        "fX[X >= xmax] = 1\n",
        "print(\"The shape of fX is\", fX.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get f(X)...\n",
            "The shape of fX is (1000, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q9:</font>\n",
        "<br><font color='green'>\n",
        "What are the hyperparameters associated with the weighting function and what is the intuition behind introducing it?\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "1ofPy91eD5UN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWbvjvDsO8Cy"
      },
      "source": [
        "---\n",
        "**Solution:**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjWn9PfcTzqW"
      },
      "source": [
        "The **cost function** can then be written as follows:\n",
        "\n",
        "\\begin{equation*}\n",
        "J = \\sum_{i=1}^V \\sum_{j=1}^V f(X_{ij}) (\\log X_{ij} - W_i^T \\tilde{W}_j - b_i - \\tilde{b}_j)^2\n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "The gradients of the cost function $J$ with respect to all the parameters are introduced in the following equations:\n",
        "\n",
        "\n",
        "For all $i \\in \\{1, \\dots, V \\}$ and all $j \\in \\{ 1, \\dots, V \\}$:\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "& \\nabla_{W_i} J(W_i) = -2 \\sum_{j'=1}^V f(X_{ij'}) \\left( \\log X_{ij'} - W_i^T \\tilde{W}_{j'} - b_i - \\tilde{b}_{j'} \\right) \\tilde{W}_{j'} \\quad \\text{(2.1)} \\\\\n",
        "& \\nabla_{\\tilde{W}_j} J(W_j) = -2 \\sum_{i'=1}^V f(X_{i' j}) \\left( \\log X_{i' j} - W_{i'}^T \\tilde{W}_j - b_{i'} - \\tilde{b}_j \\right) W_{i'} \\quad \\text{(2.2)}  \\\\\n",
        "&\\nabla_{b_i} J(b_i) = -2 \\sum_{j'=1}^V f(X_{ij'}) \\left( \\log X_{ij'} - W_i^T \\tilde{W}_{j'} - b_i - \\tilde{b}_{j'} \\right) \\quad \\text{(2.3)}  \\\\\n",
        "& \\nabla_{\\tilde{b}_j} J(\\tilde{b}_j) = -2 \\sum_{i'=1}^V f(X_{i' j}) \\left( \\log X_{i' j} - W_{i'}^T \\tilde{W}_j - b_{i'} - \\tilde{b}_j \\right) \\quad \\text{(2.4)}\n",
        "\\end{align}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q10:</font>\n",
        "<br><font color='green'>\n",
        "What is the total number of parameters in the model ? What are the shapes of all the gradients introduced in the equations (2.1), (2.2), (2.3) and (2.4) ?\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "XbzQWdyLD6Q2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDaCk9RMdYAr"
      },
      "source": [
        "---\n",
        "**Solution:**\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rZEuCrPT3cH"
      },
      "source": [
        "Let us introduce two training methods:\n",
        "\n",
        "* The first training method is called **alternating least squares**. It consists in finding the update equations by setting all the gradients to zero.\n",
        "* The second training method consists in applying the **gradient descent** algorithm.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbPZ_vBQkFdg"
      },
      "source": [
        "## 2.2 Alternating least squares"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-i1DbdJkFib"
      },
      "source": [
        "We would like to estimate the parameters $W, \\tilde{W}, b, \\tilde{b}$ by setting the gradients to zero.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q11:</font>\n",
        "<br><font color='green'>\n",
        "Show that:\n",
        "\n",
        "\\begin{align*}\n",
        "&\\nabla_{W_i} J(W_i) = 0 \\iff W_i = \\left( \\sum_{j'=1}^V f(X_{ij'}) \\tilde{W}_{j'} \\tilde{W}_{j'}^T \\right)^{-1} \\left( \\sum_{j'=1}^{V} f(X_{ij'})( \\log X_{ij'} - b_i - \\tilde{b}_{j'}) \\tilde{W}_{j'} \\right)  \\\\\n",
        "&\\nabla_{\\tilde{W}_j} J(\\tilde{W}_j) = 0 \\iff \\tilde{W}_j = \\left( \\sum_{i'=1}^V f(X_{i' j}) W_{i'} W_{i'}^T \\right)^{-1} \\left( \\sum_{i'=1}^{V} f(X_{i' j})( \\log X_{i' j} - b_{i'} - \\tilde{b}_{j}) W_{i'} \\right)  \\\\\n",
        "&\\nabla_{b_i} J(b_i) = 0 \\iff b_i = \\left( \\sum_{j'=1}^V f(X_{ij'})  \\right)^{-1} \\left( \\sum_{j'=1}^{V} f(X_{ij'})( \\log X_{ij'} - W_i^T \\tilde{W}_{j'} - \\tilde{b}_{j'}) \\right)  \\\\\n",
        "&\\nabla_{\\tilde{b}_j} J(\\tilde{b}_j) = 0 \\iff \\tilde{b}_j = \\left( \\sum_{i'=1}^V f(X_{i' j})  \\right)^{-1} \\left( \\sum_{i'=1}^{V} f(X_{i' j})( \\log X_{i' j} - W_{i'}^T \\tilde{W}_{j} - b_{i'}) \\right)\n",
        "\\end{align*}\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "InI0dBGgD7tN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Solution:**\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Fs8YgSFKXIHP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO0xwC4eXwAp"
      },
      "source": [
        "Each update equation for one parameter is a function of the other parameters. Therefore, in order to train our model, we can choose a number of iterations $N_{\\text{epochs}}$, and apply the update equations $N_{\\text{epochs}}$ times by keeping track of the loss to make sure it converges.\n",
        "\n",
        "For each iteration step $t \\in \\{0, \\dots, N_{\\text{epochs}}-1 \\}$, let $W^{(t)}, \\tilde{W}^{(t)}, b^{(t)}, \\tilde{b}^{(t)}$ represent the parameters of our model at the iteration $t$.\n",
        "\n",
        "\n",
        "The update equations from iteration $t$ to $t+1$ can then be written as follows:\n",
        "\n",
        "\\begin{align}\n",
        "&W_i^{(t+1)} \\longleftarrow \\left( \\sum_{j'=1}^V f(X_{ij'}) \\tilde{W}_{j'}^{(t)} \\tilde{W}_{j'}^{(t)^T} \\right)^{-1} \\left( \\sum_{j'=1}^{V} f(X_{ij'})( \\log X_{ij'} - b_i^{(t)} - \\tilde{b}_{j'}^{(t)}) \\tilde{W}_{j'}^{(t)} \\right) \\quad \\text{(2.5)} \\\\\n",
        "&\\tilde{W}_j^{(t+1)} \\longleftarrow \\left( \\sum_{i'=1}^V f(X_{i' j}) W_{i'}^{(t)} W_{i'}^{(t)^T} \\right)^{-1} \\left( \\sum_{i'=1}^{V} f(X_{i' j})( \\log X_{i' j} - b_{i'}^{(t)} - \\tilde{b}_{j}^{(t)}) W_{i'}^{(t)} \\right) \\quad \\text{(2.6)}  \\\\\n",
        "&b_i^{(t+1)} \\longleftarrow \\left( \\sum_{j'=1}^V f(X_{ij'})  \\right)^{-1} \\left( \\sum_{j'=1}^{V} f(X_{ij'})( \\log X_{ij'} - W_i^{(t)^T} \\tilde{W}_{j'}^{(t)} - \\tilde{b}_{j'}^{(t)}) \\right) \\quad \\text{(2.7)} \\\\\n",
        "&\\tilde{b}_j^{(t+1)} \\longleftarrow \\left( \\sum_{i'=1}^V f(X_{i' j})  \\right)^{-1} \\left( \\sum_{i'=1}^{V} f(X_{i' j})( \\log X_{i' j} - W_{i'}^{(t)^T} \\tilde{W}_{j}^{(t)} - b_{i'}^{(t)}) \\right) \\quad \\text{(2.8)}\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "\n",
        "The pseudo code for the training algorithm can be expressed as follows:\n",
        "\n",
        "\n",
        "<center><img width=\"500\" src = \"https://drive.google.com/uc?export=view&id=1DQmP3N13RH2hAP2-Szgk8TPhzcHICwGU\"></center>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q12:</font>\n",
        "<br><font color='green'>\n",
        "Implement the alternating least squares training algorithm\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "my9j51piD8-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimization Hyperparameters\n",
        "learning_rate=1e-4\n",
        "epochs = EPOCHS\n",
        "\n",
        "# initialize weights\n",
        "W = np.random.randn(V, D) / np.sqrt(V + D)\n",
        "b = np.zeros(V)\n",
        "W_tilde = np.random.randn(V, D) / np.sqrt(V + D)\n",
        "b_tilde = np.zeros(V)\n",
        "\n",
        "\n",
        "\n",
        "costs = []\n",
        "for epoch in range(epochs):\n",
        "    # epsilon (V, V) matrix such that epsilon_{ij} = logX_{ij} - W_i^T W_tilde_j - b_i - b_tilde_j\n",
        "    epsilon = logX - W.dot(W_tilde.T) - b.reshape(V, 1) - b_tilde.reshape(1, V)\n",
        "    # cost function sum_{ij} fX_{ij} (logX_{ij} - W_i^T W_tilde_j - b_i - b_tilde_j)^2 = sum_{ij} fX_{ij} epsilon_{ij}^2\n",
        "    cost = (fX * epsilon * epsilon).sum()\n",
        "    costs.append(cost)\n",
        "    print(\"epoch: {}...cost: {}\".format(epoch, cost))\n",
        "\n",
        "    # update W\n",
        "    print(\"Update W..\")\n",
        "    for i in range(V):\n",
        "        if i%1000==0:\n",
        "            print(\"Epoch {}... W is updated for {} words out of {}\".format(epoch, i, V))\n",
        "        # A = sum_{j'} fX_{ij'} W_tilde_j'  W_tilde_j'^T\n",
        "        A = (fX[i,:][None, :]*W_tilde.T).dot(W_tilde) # or A = (W_tilde.T).dot(W_tilde*(fX[i, :][:, None]))\n",
        "        # B = sum_{j'} fX_{ij'} (logX_{ij'} - b_i - b_tilde_j') W_tilde_j'\n",
        "        B = (fX[i, :]*(logX[i, :] - b[i] - b_tilde)).dot(W_tilde)\n",
        "        # W_i = A^{-1} B\n",
        "        W[i] = np.linalg.solve(A, B)\n",
        "\n",
        "\n",
        "    # update b\n",
        "    print(\"Update b..\")\n",
        "    for i in range(V):\n",
        "        if i%1000==0:\n",
        "            print(\"Epoch {}... b is updated for {} words out of {}\".format(epoch, i, V))\n",
        "        # A = sum_{j'} fX_{ij'}\n",
        "        A = fX[i, :].sum()\n",
        "        # B = sum_{j'} fX_{ij'} (logX_{ij'} - W_i^T W_tilde_j' - b_tilde_j')\n",
        "        B = fX[i, :].dot(logX[i, :] - W[i].dot(W_tilde.T) - b_tilde)\n",
        "        # b_i = A^{-1} B\n",
        "        b[i] = B/A\n",
        "\n",
        "    # update W_tilde\n",
        "    print(\"Update W_tilde..\")\n",
        "    for j in range(V):\n",
        "        if j%1000==0:\n",
        "            print(\"Epoch {}... W_tilde is updated for {} words out of {}\".format(epoch, j, V))\n",
        "        # A = sum_{i'} fX_{i'j} W_i'  W_i'^T\n",
        "        A = (fX[:, j][None, :]*(W.T)).dot(W)\n",
        "        # B = sum_{i'} fX_{i'j} (logX_{i'j} - b_i' - b_tilde_j) W_i'\n",
        "        B = (fX[:, j]*(logX[:, j] - b - b_tilde[j])).dot(W)\n",
        "        # W_tilde_j = A^{-1} B\n",
        "        W_tilde[j] = np.linalg.solve(A, B)\n",
        "\n",
        "\n",
        "    # update b_tilde\n",
        "    print(\"Update b_tilde..\")\n",
        "    for j in range(V):\n",
        "        if j%1000==0:\n",
        "            print(\"Epoch {}... b_tilde is updated for {} words out of {}\".format(epoch, j, V))\n",
        "        # A = sum_{i'} fX_{i'j}\n",
        "        A = fX[:, j].sum()\n",
        "        # B = sum_{i'} fX_{i'j} (logX_{i'j} - W_i'^T W_tilde_j - b_i')\n",
        "        B = fX[:, j].dot(logX[:, j] - W.dot(W_tilde[j]) - b)\n",
        "        # b_tilde_j = A^{-1} B\n",
        "        b_tilde[j] = B/A\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62nQJ9gmaNk_",
        "outputId": "3ccd09f5-2c0d-4b2b-e0be-722d9d931690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0...cost: 436187.7916809894\n",
            "Update W..\n",
            "Epoch 0... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 0... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 0... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 0... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 1...cost: 5159.519522265242\n",
            "Update W..\n",
            "Epoch 1... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 1... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 1... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 1... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 2...cost: 2811.2111745297793\n",
            "Update W..\n",
            "Epoch 2... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 2... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 2... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 2... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 3...cost: 2485.127785717547\n",
            "Update W..\n",
            "Epoch 3... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 3... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 3... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 3... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 4...cost: 2366.360115127894\n",
            "Update W..\n",
            "Epoch 4... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 4... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 4... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 4... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 5...cost: 2307.779313549681\n",
            "Update W..\n",
            "Epoch 5... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 5... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 5... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 5... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 6...cost: 2273.8091155453862\n",
            "Update W..\n",
            "Epoch 6... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 6... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 6... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 6... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 7...cost: 2251.8520197764833\n",
            "Update W..\n",
            "Epoch 7... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 7... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 7... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 7... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 8...cost: 2236.480857889092\n",
            "Update W..\n",
            "Epoch 8... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 8... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 8... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 8... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 9...cost: 2225.0680233226194\n",
            "Update W..\n",
            "Epoch 9... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 9... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 9... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 9... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 10...cost: 2216.2103907564237\n",
            "Update W..\n",
            "Epoch 10... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 10... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 10... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 10... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 11...cost: 2209.095009106139\n",
            "Update W..\n",
            "Epoch 11... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 11... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 11... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 11... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 12...cost: 2203.223599273789\n",
            "Update W..\n",
            "Epoch 12... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 12... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 12... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 12... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 13...cost: 2198.2792070668943\n",
            "Update W..\n",
            "Epoch 13... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 13... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 13... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 13... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 14...cost: 2194.053416493986\n",
            "Update W..\n",
            "Epoch 14... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 14... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 14... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 14... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 15...cost: 2190.4031412304066\n",
            "Update W..\n",
            "Epoch 15... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 15... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 15... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 15... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 16...cost: 2187.2246903693763\n",
            "Update W..\n",
            "Epoch 16... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 16... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 16... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 16... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 17...cost: 2184.439002363787\n",
            "Update W..\n",
            "Epoch 17... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 17... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 17... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 17... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 18...cost: 2181.9836388600183\n",
            "Update W..\n",
            "Epoch 18... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 18... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 18... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 18... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 19...cost: 2179.8082427503505\n",
            "Update W..\n",
            "Epoch 19... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 19... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 19... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 19... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 20...cost: 2177.871585608685\n",
            "Update W..\n",
            "Epoch 20... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 20... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 20... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 20... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 21...cost: 2176.1394598622196\n",
            "Update W..\n",
            "Epoch 21... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 21... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 21... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 21... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 22...cost: 2174.5831744594384\n",
            "Update W..\n",
            "Epoch 22... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 22... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 22... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 22... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 23...cost: 2173.17850855745\n",
            "Update W..\n",
            "Epoch 23... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 23... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 23... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 23... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 24...cost: 2171.904968646858\n",
            "Update W..\n",
            "Epoch 24... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 24... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 24... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 24... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 25...cost: 2170.745214225084\n",
            "Update W..\n",
            "Epoch 25... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 25... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 25... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 25... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 26...cost: 2169.6845685659528\n",
            "Update W..\n",
            "Epoch 26... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 26... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 26... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 26... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 27...cost: 2168.7105821008076\n",
            "Update W..\n",
            "Epoch 27... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 27... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 27... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 27... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 28...cost: 2167.8126466792473\n",
            "Update W..\n",
            "Epoch 28... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 28... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 28... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 28... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 29...cost: 2166.9816682903765\n",
            "Update W..\n",
            "Epoch 29... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 29... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 29... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 29... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 30...cost: 2166.2098020790527\n",
            "Update W..\n",
            "Epoch 30... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 30... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 30... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 30... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 31...cost: 2165.4902458507636\n",
            "Update W..\n",
            "Epoch 31... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 31... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 31... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 31... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 32...cost: 2164.8170823949995\n",
            "Update W..\n",
            "Epoch 32... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 32... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 32... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 32... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 33...cost: 2164.185158685047\n",
            "Update W..\n",
            "Epoch 33... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 33... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 33... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 33... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 34...cost: 2163.5899907489315\n",
            "Update W..\n",
            "Epoch 34... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 34... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 34... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 34... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 35...cost: 2163.0276853572905\n",
            "Update W..\n",
            "Epoch 35... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 35... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 35... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 35... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 36...cost: 2162.4948724049195\n",
            "Update W..\n",
            "Epoch 36... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 36... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 36... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 36... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 37...cost: 2161.988644237644\n",
            "Update W..\n",
            "Epoch 37... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 37... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 37... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 37... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 38...cost: 2161.506499916931\n",
            "Update W..\n",
            "Epoch 38... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 38... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 38... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 38... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 39...cost: 2161.0462935307783\n",
            "Update W..\n",
            "Epoch 39... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 39... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 39... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 39... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 40...cost: 2160.606186288484\n",
            "Update W..\n",
            "Epoch 40... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 40... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 40... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 40... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 41...cost: 2160.1846024380097\n",
            "Update W..\n",
            "Epoch 41... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 41... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 41... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 41... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 42...cost: 2159.780189149294\n",
            "Update W..\n",
            "Epoch 42... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 42... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 42... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 42... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 43...cost: 2159.391780504068\n",
            "Update W..\n",
            "Epoch 43... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 43... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 43... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 43... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 44...cost: 2159.0183656744744\n",
            "Update W..\n",
            "Epoch 44... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 44... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 44... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 44... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 45...cost: 2158.65906128672\n",
            "Update W..\n",
            "Epoch 45... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 45... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 45... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 45... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 46...cost: 2158.3130878667193\n",
            "Update W..\n",
            "Epoch 46... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 46... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 46... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 46... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 47...cost: 2157.979750163247\n",
            "Update W..\n",
            "Epoch 47... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 47... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 47... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 47... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 48...cost: 2157.658421050361\n",
            "Update W..\n",
            "Epoch 48... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 48... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 48... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 48... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 49...cost: 2157.348528635172\n",
            "Update W..\n",
            "Epoch 49... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 49... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 49... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 49... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 50...cost: 2157.0495461467945\n",
            "Update W..\n",
            "Epoch 50... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 50... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 50... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 50... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 51...cost: 2156.7609841619287\n",
            "Update W..\n",
            "Epoch 51... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 51... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 51... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 51... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 52...cost: 2156.482384730473\n",
            "Update W..\n",
            "Epoch 52... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 52... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 52... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 52... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 53...cost: 2156.2133169965173\n",
            "Update W..\n",
            "Epoch 53... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 53... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 53... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 53... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 54...cost: 2155.9533739581107\n",
            "Update W..\n",
            "Epoch 54... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 54... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 54... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 54... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 55...cost: 2155.7021700658393\n",
            "Update W..\n",
            "Epoch 55... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 55... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 55... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 55... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 56...cost: 2155.4593394183676\n",
            "Update W..\n",
            "Epoch 56... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 56... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 56... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 56... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 57...cost: 2155.224534367594\n",
            "Update W..\n",
            "Epoch 57... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 57... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 57... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 57... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 58...cost: 2154.997424393985\n",
            "Update W..\n",
            "Epoch 58... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 58... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 58... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 58... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 59...cost: 2154.777695152372\n",
            "Update W..\n",
            "Epoch 59... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 59... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 59... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 59... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 60...cost: 2154.565047620188\n",
            "Update W..\n",
            "Epoch 60... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 60... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 60... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 60... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 61...cost: 2154.3591973043244\n",
            "Update W..\n",
            "Epoch 61... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 61... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 61... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 61... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 62...cost: 2154.159873480622\n",
            "Update W..\n",
            "Epoch 62... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 62... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 62... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 62... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 63...cost: 2153.966818452613\n",
            "Update W..\n",
            "Epoch 63... W is updated for 0 words out of 1000\n",
            "Update b..\n",
            "Epoch 63... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 63... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 63... b_tilde is updated for 0 words out of 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q13:</font>\n",
        "<br><font color='green'>\n",
        " Plot the list of losses at the end of each iteration in Algorithm 3.\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0cmFRYw-D95S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "plt.plot(costs)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"cost\")\n",
        "plt.title(\"Cost function using ALS\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "L7br03pNbwRG",
        "outputId": "3a1c104f-0ba5-4a30-aec9-2161636b75d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX56bVMHkFnd"
      },
      "source": [
        "## 2.3 Learning the weights using gradient descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Luje3fIdkFsY"
      },
      "source": [
        "In this section, we would like to estimate the parameters of the model using gradient descent.\n",
        "\n",
        "Let $N_{\\text{epochs}}$ be the number of epochs and $\\eta$ be the learning rate.\n",
        "We get the following training algorithm:\n",
        "\n",
        "\n",
        "<center><img width=\"500\" src = \"https://drive.google.com/uc?export=view&id=1Od3xCvMWKOBhMpccmKOtoY3aT3UTJB5Z\"></center>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q14:</font>\n",
        "<br><font color='green'>\n",
        "Implement the gradient descent training algorithm (Algorithm 4).\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "85Ih7k7OD-py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize weights\n",
        "W = np.random.randn(V, D) / np.sqrt(V + D)\n",
        "b = np.zeros(V)\n",
        "W_tilde = np.random.randn(V,D) / np.sqrt(V + D)\n",
        "b_tilde = np.zeros(V)\n",
        "\n",
        "\n",
        "costs = []\n",
        "for epoch in range(epochs):\n",
        "    # epsilon (V, V) matrix such that epsilon_{ij} = logX_{ij} - W_i^T W_tilde_j - b_i - b_tilde_j\n",
        "    epsilon = logX - W.dot(W_tilde.T) - b.reshape(V, 1) - b_tilde.reshape(1, V)\n",
        "    # cost function sum_{ij} fX_{ij} (logX_{ij} - W_i^T W_tilde_j - b_i - b_tilde_j)^2 = sum_{ij} fX_{ij} epsilon_{ij}^2\n",
        "    cost = (fX * epsilon * epsilon).sum()\n",
        "    costs.append(cost)\n",
        "    print(\"epoch: {}...cost: {}\".format(epoch, cost))\n",
        "\n",
        "    # Update W\n",
        "    print(\"Update W..\")\n",
        "    for i in range(V):\n",
        "        if i%1000==0:\n",
        "            print(\"Epoch {}... W is updated for {} words out of {}\".format(epoch, i, V))\n",
        "        # W_i -= learning_rate*(-2*sum_{j'} fX_{i,j'}*epsilon_{i,j'}*W_tilde_j')\n",
        "        W[i] -= -2*learning_rate*(fX[i,:]*epsilon[i,:]).dot(W_tilde)\n",
        "\n",
        "\n",
        "    # update b\n",
        "    for i in range(V):\n",
        "        if i%1000==0:\n",
        "            print(\"Epoch {}... b is updated for {} words out of {}\".format(epoch, i, V))\n",
        "        # b_i -= learning_rate*(-2*sum_{j'} fX_{i,j'}*epsilon_{i,j'}\n",
        "        b[i] -= -2*learning_rate*fX[i,:].dot(epsilon[i,:])\n",
        "\n",
        "\n",
        "    # update W_tilde\n",
        "    print(\"Update W_tilde..\")\n",
        "    for j in range(V):\n",
        "        if j%1000==0:\n",
        "            print(\"Epoch {}... W_tilde is updated for {} words out of {}\".format(epoch, j, V))\n",
        "        # W_tilde_j -= learning_rate*(-2*sum_{i'} fX_{i',j}*epsilon_{i',j}*W_i')\n",
        "        W_tilde[j] -= -2*learning_rate*(fX[:,j]*epsilon[:,j]).dot(W)\n",
        "\n",
        "\n",
        "    # update b_tilde\n",
        "    print(\"Update b_tilde..\")\n",
        "    for j in range(V):\n",
        "        if j%1000==0:\n",
        "            print(\"Epoch {}... b_tilde is updated for {} words out of {}\".format(epoch, j, V))\n",
        "        # b_tilde_j -= learning_rate*(-2*sum_{i'} fX_{i',j}*epsilon_{i',j})\n",
        "        b_tilde[j] -= -2*learning_rate*fX[:,j].dot(epsilon[:,j])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY4e1IP3mKL4",
        "outputId": "e8bb8ed4-20ec-4a2b-8bbe-bba77f5cc518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0...cost: 436210.65428016626\n",
            "Update W..\n",
            "Epoch 0... W is updated for 0 words out of 1000\n",
            "Epoch 0... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 0... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 0... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 1...cost: 344887.0507655743\n",
            "Update W..\n",
            "Epoch 1... W is updated for 0 words out of 1000\n",
            "Epoch 1... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 1... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 1... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 2...cost: 278235.1153953154\n",
            "Update W..\n",
            "Epoch 2... W is updated for 0 words out of 1000\n",
            "Epoch 2... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 2... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 2... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 3...cost: 228952.9404425676\n",
            "Update W..\n",
            "Epoch 3... W is updated for 0 words out of 1000\n",
            "Epoch 3... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 3... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 3... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 4...cost: 192018.98599797726\n",
            "Update W..\n",
            "Epoch 4... W is updated for 0 words out of 1000\n",
            "Epoch 4... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 4... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 4... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 5...cost: 163952.66677819224\n",
            "Update W..\n",
            "Epoch 5... W is updated for 0 words out of 1000\n",
            "Epoch 5... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 5... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 5... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 6...cost: 142321.5242337528\n",
            "Update W..\n",
            "Epoch 6... W is updated for 0 words out of 1000\n",
            "Epoch 6... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 6... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 6... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 7...cost: 125410.9812878623\n",
            "Update W..\n",
            "Epoch 7... W is updated for 0 words out of 1000\n",
            "Epoch 7... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 7... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 7... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 8...cost: 112001.75760995602\n",
            "Update W..\n",
            "Epoch 8... W is updated for 0 words out of 1000\n",
            "Epoch 8... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 8... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 8... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 9...cost: 101218.9138335793\n",
            "Update W..\n",
            "Epoch 9... W is updated for 0 words out of 1000\n",
            "Epoch 9... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 9... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 9... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 10...cost: 92428.79742468598\n",
            "Update W..\n",
            "Epoch 10... W is updated for 0 words out of 1000\n",
            "Epoch 10... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 10... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 10... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 11...cost: 85168.20087922545\n",
            "Update W..\n",
            "Epoch 11... W is updated for 0 words out of 1000\n",
            "Epoch 11... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 11... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 11... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 12...cost: 79095.31089533232\n",
            "Update W..\n",
            "Epoch 12... W is updated for 0 words out of 1000\n",
            "Epoch 12... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 12... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 12... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 13...cost: 73955.49209935874\n",
            "Update W..\n",
            "Epoch 13... W is updated for 0 words out of 1000\n",
            "Epoch 13... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 13... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 13... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 14...cost: 69557.23694919434\n",
            "Update W..\n",
            "Epoch 14... W is updated for 0 words out of 1000\n",
            "Epoch 14... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 14... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 14... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 15...cost: 65755.13091539725\n",
            "Update W..\n",
            "Epoch 15... W is updated for 0 words out of 1000\n",
            "Epoch 15... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 15... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 15... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 16...cost: 62437.69325482707\n",
            "Update W..\n",
            "Epoch 16... W is updated for 0 words out of 1000\n",
            "Epoch 16... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 16... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 16... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 17...cost: 59518.6310238639\n",
            "Update W..\n",
            "Epoch 17... W is updated for 0 words out of 1000\n",
            "Epoch 17... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 17... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 17... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 18...cost: 56930.50019042303\n",
            "Update W..\n",
            "Epoch 18... W is updated for 0 words out of 1000\n",
            "Epoch 18... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 18... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 18... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 19...cost: 54620.076801315554\n",
            "Update W..\n",
            "Epoch 19... W is updated for 0 words out of 1000\n",
            "Epoch 19... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 19... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 19... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 20...cost: 52544.95189208559\n",
            "Update W..\n",
            "Epoch 20... W is updated for 0 words out of 1000\n",
            "Epoch 20... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 20... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 20... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 21...cost: 50671.00843100468\n",
            "Update W..\n",
            "Epoch 21... W is updated for 0 words out of 1000\n",
            "Epoch 21... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 21... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 21... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 22...cost: 48970.538485418365\n",
            "Update W..\n",
            "Epoch 22... W is updated for 0 words out of 1000\n",
            "Epoch 22... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 22... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 22... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 23...cost: 47420.82828425051\n",
            "Update W..\n",
            "Epoch 23... W is updated for 0 words out of 1000\n",
            "Epoch 23... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 23... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 23... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 24...cost: 46003.087518782864\n",
            "Update W..\n",
            "Epoch 24... W is updated for 0 words out of 1000\n",
            "Epoch 24... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 24... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 24... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 25...cost: 44701.633548312\n",
            "Update W..\n",
            "Epoch 25... W is updated for 0 words out of 1000\n",
            "Epoch 25... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 25... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 25... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 26...cost: 43503.265551878445\n",
            "Update W..\n",
            "Epoch 26... W is updated for 0 words out of 1000\n",
            "Epoch 26... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 26... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 26... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 27...cost: 42396.78109293061\n",
            "Update W..\n",
            "Epoch 27... W is updated for 0 words out of 1000\n",
            "Epoch 27... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 27... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 27... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 28...cost: 41372.60010330675\n",
            "Update W..\n",
            "Epoch 28... W is updated for 0 words out of 1000\n",
            "Epoch 28... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 28... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 28... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 29...cost: 40422.470373543096\n",
            "Update W..\n",
            "Epoch 29... W is updated for 0 words out of 1000\n",
            "Epoch 29... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 29... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 29... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 30...cost: 39539.23525238796\n",
            "Update W..\n",
            "Epoch 30... W is updated for 0 words out of 1000\n",
            "Epoch 30... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 30... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 30... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 31...cost: 38716.64910662137\n",
            "Update W..\n",
            "Epoch 31... W is updated for 0 words out of 1000\n",
            "Epoch 31... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 31... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 31... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 32...cost: 37949.229664922736\n",
            "Update W..\n",
            "Epoch 32... W is updated for 0 words out of 1000\n",
            "Epoch 32... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 32... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 32... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 33...cost: 37232.13901620882\n",
            "Update W..\n",
            "Epoch 33... W is updated for 0 words out of 1000\n",
            "Epoch 33... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 33... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 33... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 34...cost: 36561.087003559776\n",
            "Update W..\n",
            "Epoch 34... W is updated for 0 words out of 1000\n",
            "Epoch 34... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 34... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 34... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 35...cost: 35932.25222939755\n",
            "Update W..\n",
            "Epoch 35... W is updated for 0 words out of 1000\n",
            "Epoch 35... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 35... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 35... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 36...cost: 35342.21699610317\n",
            "Update W..\n",
            "Epoch 36... W is updated for 0 words out of 1000\n",
            "Epoch 36... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 36... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 36... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 37...cost: 34787.91334345029\n",
            "Update W..\n",
            "Epoch 37... W is updated for 0 words out of 1000\n",
            "Epoch 37... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 37... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 37... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 38...cost: 34266.577979353635\n",
            "Update W..\n",
            "Epoch 38... W is updated for 0 words out of 1000\n",
            "Epoch 38... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 38... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 38... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 39...cost: 33775.7143844015\n",
            "Update W..\n",
            "Epoch 39... W is updated for 0 words out of 1000\n",
            "Epoch 39... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 39... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 39... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 40...cost: 33313.06074107008\n",
            "Update W..\n",
            "Epoch 40... W is updated for 0 words out of 1000\n",
            "Epoch 40... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 40... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 40... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 41...cost: 32876.562623308455\n",
            "Update W..\n",
            "Epoch 41... W is updated for 0 words out of 1000\n",
            "Epoch 41... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 41... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 41... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 42...cost: 32464.34960211669\n",
            "Update W..\n",
            "Epoch 42... W is updated for 0 words out of 1000\n",
            "Epoch 42... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 42... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 42... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 43...cost: 32074.715093371025\n",
            "Update W..\n",
            "Epoch 43... W is updated for 0 words out of 1000\n",
            "Epoch 43... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 43... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 43... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 44...cost: 31706.09890714846\n",
            "Update W..\n",
            "Epoch 44... W is updated for 0 words out of 1000\n",
            "Epoch 44... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 44... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 44... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 45...cost: 31357.07206196742\n",
            "Update W..\n",
            "Epoch 45... W is updated for 0 words out of 1000\n",
            "Epoch 45... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 45... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 45... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 46...cost: 31026.323509345293\n",
            "Update W..\n",
            "Epoch 46... W is updated for 0 words out of 1000\n",
            "Epoch 46... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 46... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 46... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 47...cost: 30712.648478927502\n",
            "Update W..\n",
            "Epoch 47... W is updated for 0 words out of 1000\n",
            "Epoch 47... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 47... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 47... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 48...cost: 30414.938206010294\n",
            "Update W..\n",
            "Epoch 48... W is updated for 0 words out of 1000\n",
            "Epoch 48... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 48... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 48... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 49...cost: 30132.170844503788\n",
            "Update W..\n",
            "Epoch 49... W is updated for 0 words out of 1000\n",
            "Epoch 49... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 49... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 49... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 50...cost: 29863.40340151121\n",
            "Update W..\n",
            "Epoch 50... W is updated for 0 words out of 1000\n",
            "Epoch 50... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 50... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 50... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 51...cost: 29607.764556475522\n",
            "Update W..\n",
            "Epoch 51... W is updated for 0 words out of 1000\n",
            "Epoch 51... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 51... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 51... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 52...cost: 29364.448249600824\n",
            "Update W..\n",
            "Epoch 52... W is updated for 0 words out of 1000\n",
            "Epoch 52... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 52... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 52... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 53...cost: 29132.70794203514\n",
            "Update W..\n",
            "Epoch 53... W is updated for 0 words out of 1000\n",
            "Epoch 53... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 53... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 53... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 54...cost: 28911.851464909043\n",
            "Update W..\n",
            "Epoch 54... W is updated for 0 words out of 1000\n",
            "Epoch 54... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 54... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 54... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 55...cost: 28701.23638639519\n",
            "Update W..\n",
            "Epoch 55... W is updated for 0 words out of 1000\n",
            "Epoch 55... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 55... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 55... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 56...cost: 28500.26583598196\n",
            "Update W..\n",
            "Epoch 56... W is updated for 0 words out of 1000\n",
            "Epoch 56... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 56... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 56... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 57...cost: 28308.384733527484\n",
            "Update W..\n",
            "Epoch 57... W is updated for 0 words out of 1000\n",
            "Epoch 57... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 57... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 57... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 58...cost: 28125.076377693924\n",
            "Update W..\n",
            "Epoch 58... W is updated for 0 words out of 1000\n",
            "Epoch 58... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 58... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 58... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 59...cost: 27949.85935429273\n",
            "Update W..\n",
            "Epoch 59... W is updated for 0 words out of 1000\n",
            "Epoch 59... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 59... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 59... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 60...cost: 27782.28473010336\n",
            "Update W..\n",
            "Epoch 60... W is updated for 0 words out of 1000\n",
            "Epoch 60... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 60... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 60... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 61...cost: 27621.93350201243\n",
            "Update W..\n",
            "Epoch 61... W is updated for 0 words out of 1000\n",
            "Epoch 61... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 61... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 61... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 62...cost: 27468.41427498876\n",
            "Update W..\n",
            "Epoch 62... W is updated for 0 words out of 1000\n",
            "Epoch 62... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 62... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 62... b_tilde is updated for 0 words out of 1000\n",
            "epoch: 63...cost: 27321.361145558312\n",
            "Update W..\n",
            "Epoch 63... W is updated for 0 words out of 1000\n",
            "Epoch 63... b is updated for 0 words out of 1000\n",
            "Update W_tilde..\n",
            "Epoch 63... W_tilde is updated for 0 words out of 1000\n",
            "Update b_tilde..\n",
            "Epoch 63... b_tilde is updated for 0 words out of 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q15:</font>\n",
        "<br><font color='green'>\n",
        " Plot the list of losses at the end of each iteration in Algorithm 4.\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6aS7uO42D_Ya"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VRIWLWrmfnR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "355ac078-7649-4306-de6d-e2abab1d9e50"
      },
      "source": [
        "# Plot the costs for each epoch\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "plt.plot(costs)\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"cost\")\n",
        "plt.title(\"Cost function using gradient descent\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2wAAAJwCAYAAAD1D+IFAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAgjxJREFUeJzs3Xl4VOXd//FP9kCYhDUJ+06Q3URE3IIgiAtaBbHVVqiPPqA+Vdv+CqK2iq0LWEELIiqKtiLWiiuoKAoKGFBDhSDImkQI2ZfJwkzW+/dHMgeGBAgYOJPk/bqu75WZc+458505oPlwzrmPnyQjAAAAAIDP8be7AQAAAABA3QhsAAAAAOCjCGwAAAAA4KMIbAAAAADgowhsAAAAAOCjCGwAAAAA4KMIbAAAAADgowhsAAAAAOCjCGwAAAAA4KMIbADQyPXp00erV69WQUGBjDG67rrr7G6pTmvXrtXatWvtbuNnM8bo4YcftrsN2xy7H7t37y5jjKZMmWJjV/XTmHoFAA8CGwCcQK9evbR48WLt27dPLpdLTqdTGzZs0D333KPQ0NAGf78WLVro4YcfVnx8fL1f89prr2nw4MF68MEH9etf/1rfffddg/dVX+ecc44efvhhde/e3bYe0DTdeeedBK3j+NWvfqV7773X7jYAnEGGoiiKql1XXXWVKSkpMXl5eeaZZ54xt99+u7nrrrvMG2+8YUpLS80LL7zQ4O/Zrl07Y4wxDz/8cL3Gh4aGGmOM+etf/2r79yXJTJw40RhjTHx8fK11QUFBJigoyPYef26FhISYgIAA2/uwq9auXWvWrl1b6zvx9/c/o++blJRU631Ptbp3726MMWbKlCm2f48NWR9++KFJTk62vQ+Kos5MBQoAUEuPHj305ptvKjU1VaNHj1ZGRoa1btGiRerdu7euvvpqGzus1qFDB0lSQUGBvY3UQ3l5ud0tNIjS0lK7WzgtLVq0kMvlOiPbbqzfCQA0FranRoqiKF+rRYsWGWOMGTlyZL3GBwQEmIceesjs3bvXuN1uk5ycbB577DETHBzsNS4uLs588sknJjs72xw+fNjs37/fvPzyy0Y68q//xzre0baHH3641ljPv7IvXbq0zn9x97zm6GXGGLNgwQJz3XXXmaSkJON2u8327dvNFVdcUev1nTp1MkuWLDFpaWnG7Xab/fv3m0WLFpmgoCAzZcqUOvv3HG2r68hMhw4dzJIlS0xGRoZxuVzm+++/N7feeqvXGM/38sc//tHccccd1nf8zTffmPPOO++k+6auzyzJ6rd79+712j9Hf19H7xPP9nv37m2WLl1q8vPzTUFBgXnllVdMixYtvF4bGhpqnn32WZOdnW0KCwvN+++/bzp16lTvo6rdunUz77//vikuLjaZmZlm3rx5Zty4cbWOaq5du9YkJSWZ2NhY8+WXX5qSkhIzf/58I8lce+21ZuXKldY+3Lt3r3nooYfqPELm+b4PHz5sNm/ebC6++OJa+/F4R61iYmLMf/7zH5Obm2tcLpf59ttvzYQJE+rcBxdeeKF5+umnTVZWlikuLjbvvPOOad++vTUuOTm51p+rkx1ti4iIMEuXLjUFBQUmPz/fvPrqq2bo0KGn3WtgYKD5y1/+Ynbv3m1cLpfJyckx69evN5dffnmtbf373/82WVlZ5vDhw+bHH380f/vb32r9PXr55ZdNRkaG9fftt7/9rdeY+Ph4Y4wxN954o3nggQfMgQMHjMvlMmvWrDG9e/f22tfH++8ARVFNozjCBgB1mDBhgvbt26eEhIR6jV+yZImmTp2q//znP3r66ac1YsQIPfDAAzrnnHN0ww03SKo+Gvbpp58qOztbTz75pAoKCtSjRw9rfXZ2tqZPn67FixfrnXfe0TvvvCNJ2rZtW53v+c4776igoEDPPPOM3njjDX300UcqLi4+rc978cUX64YbbtCiRYtUVFSke+65RytWrFC3bt2Ul5cnSerYsaO++eYbtW7dWi+++KJ+/PFHde7cWZMmTVLLli311Vdf6dlnn9W9996rxx57TDt37pQk6+exQkNDtW7dOvXp00cLFy5UcnKybrzxRr322mtq3bq1/vGPf3iNv/nmm+VwOPTCCy/IGKMZM2bonXfeUa9evVRRUXFan/toJ9s/J/PWW28pOTlZs2bNUmxsrO644w5lZWXp/vvvt8a8+uqruummm/TPf/5TmzZtUnx8vFatWlWv7bds2VJffPGFOnbsqGeffVYZGRm6+eabddlll9U5vl27dvr444/15ptv6vXXX1dmZqYkaerUqSouLta8efNUXFys0aNH669//avCw8M1Y8YM6/W33XabXnzxRW3cuFHPPPOMevXqpQ8++EB5eXk6cODACXsdMGCANm7cqLS0ND355JMqKSnR5MmT9d5772nixIl67733vMYvWLBA+fn5mj17tnr06KH77rtPCxcu1C9/+UtJ0n333acFCxaouLhYjz32mCRZn+d43n//fV188cVavHixdu7cqeuvv16vvfbaaff6yCOPaNasWVqyZIm++eYbhYeH67zzzlNsbKzWrFkjSRo8eLDWr1+v8vJyvfjii0pJSVHv3r01YcIEPfTQQ5KkyMhIbdq0ScYYLVy4UNnZ2bryyiv1yiuvKDw8XM8++6xXf/fff7+qqqr097//XREREZoxY4aWLVumCy64QJL02GOPKSIiQl26dNHvf/97STrt/w4A8F22p0aKoihfKofDYYwx5t13363X+CFDhhhjjHnxxRe9ls+dO9cYY8yoUaOMJHPdddcZY4yJi4s77rZO9Rq2o48+Hb38VI+wud1u06tXL2vZ4MGDjTHG3H333dayV1991VRUVJyw/xNdw3bskZl77rnHGGPMzTffbC0LDAw0GzduNIWFhaZVq1ZenzE7O9u0bt3aGjthwgRjjDFXX331Cb+j+h5hq8/+8XxfdR1hW7Jkide4FStWmOzsbOv5ueeea4wxZt68eV7jXnnllXrt89///vfGGGOuvfZaa1lISIjZsWNHnUfYjDHmf//3f2ttJzQ0tNay559/3hQXF1tHhAMDA01GRobZsmWL13WHt99+e62jW3UdYfvss8/M1q1bax1h3rBhg9m1a1etffDpp596jXv66adNeXm5CQ8Pt5adyjVs1157rTHGmP/3//6ftczf3998+eWXp93rf//7X/Phhx+e8H3XrVtnnE6n6dq163HHvPTSSyYtLc20bdvWa/kbb7xh8vPzrf3jOcL2ww8/eO2D3/3ud8YYYwYOHGgt4xo2imraxSyRAHCM8PBwSVJRUVG9xl911VWSpHnz5nktf/rppyXJutbNc53ZNddco8BA3zrBYc2aNdq/f7/1PCkpSU6nU7169ZIk+fn56Re/+IU+/PBDJSYmNsh7XnXVVUpPT9fy5cutZRUVFfrHP/4hh8NRa6bMf//7317X6q1fv16SrB5/rp+7fxYvXuz1fP369Wrfvr0cDockafz48ZKqr4E82oIFC+q1/fHjx+vgwYP64IMPrGWlpaV66aWX6hzvdru1dOnSOpd7tGrVSu3atdP69esVFham/v37S5LOO+88RUVFafHixV7XHr766qsnvV6yTZs2Gj16tN566y05HA61a9fOqtWrV6tfv37q1KmT12tefPFFr+fr169XYGDgac82etVVV6m8vFzPP/+8tayqqqrWd30qvRYUFGjgwIHq06dPne/Zvn17xcfH65VXXjnhEciJEyfqww8/lJ+fX633a926tWJjY73GL1261GsfNPSfewC+j8AGAMcoLCyUJOsX7ZPp3r27KisrtXfvXq/lmZmZys/Pt37p/PLLL/X222/rkUceUU5Ojt577z1NnTpVwcHBDfsBTsNPP/1Ua1l+fr7atGkjqfp0wYiICG3fvr3B3rN79+7as2ePqg9+HeE5hfLYX9aP7dETHDw9/lw/d/8c219+fr5Xf54/J8nJyV7jjv1zczzdu3fXvn37ai0/3uvT0tLqnOhlwIAB1um0RUVFysnJ0bJlyyRJERER1ntJ0p49e7xeW1FR4RXs69KnTx/5+/vrb3/7m3Jycrzq0UcflVR9WuDRTvbdnaru3bsrPT1dJSUlXst37dp12r3+5S9/UevWrbVnzx5t27ZNc+fO1eDBg61teQLUif6OdOjQQW3atNG0adNqvd+rr77q9X4eDf3dAGh8fOufeAHABxQVFSktLU2DBg06pdcdGzzqcuONN2rEiBGaMGGCrrjiCi1dulR//OMfdcEFF9T65fLnOF4vAQEBdS6vrKysc7mfn1+D9fRznW6Pp/Jd/Jz942vfYV0zQkZEROjLL79UYWGh/vKXv2jfvn1yu92KjY3V3Llz5e//8/8d17ONp556SqtXr65zzLEh067v7lR6Xb9+vXr37q3rrrtO48aN0+23367f//73mj59ul5++eVTer9//etfdV5PJ9W+ZtXX/lwBOPsIbABQh5UrV2ratGm64IILtGnTphOOTU1NVUBAgPr27asff/zRWh4ZGak2bdooNTXVa/zmzZu1efNmPfTQQ/rVr36lN954Q7/85S/18ssv1yv01Ud+fr5at25da/npnmKWnZ0tp9N50hB7Kv2npqZqyJAh8vPz83qd57S8Y7+30+U5IhERESGn02ktP953caL983N4/pz07NnTK7Ac7xS7ul4/YMCAWsvr+3pJGjVqlNq3b68bbrjBOrVOknr27FnrvSSpb9++Wrt2rbU8MDBQPXv21NatW4/7Hp4jcOXl5fr888/r3dvJnOqfrTFjxigsLMwraMfExHiNO9Ve8/Pz9eqrr+rVV19VWFiYvvrqKz3yyCN6+eWXrW2d6O9Idna2CgsLFRAQYNt3A6Dx4ZRIAKjD3LlzVVxcrCVLltQ6RUmqPv3pnnvukSR99NFHkqpnsjvaH/7wB0myZgGsK0B9//33kqSQkBBJ0uHDh4879lTs27dPrVu39jplKzo6Wtdff/1pbc8Yo/fee08TJkxQXFzcccd5fjmuT/8fffSROnbsqJtuuslaFhAQoN/97ncqKirSl19+eVq9HstzGuGll15qLWvZsqWmTJniNa4+++fn8BzBueuuu7yW/+53v6v367t06aJrr73WWhYSEqI77rij3j14jtYcfXQmKCioVk/fffedsrKyNH36dAUFBVnLp06detJT8bKzs7V27VpNmzZN0dHRtda3b9++3v0eraSkpN5/Lz766CMFBQXpzjvvtJb5+/vX+q5Ppde2bdvW6mfv3r3Wn42cnBx9+eWXuu2229S1a9c6+6qqqtKKFSs0ceJEDRw48ITvdypKSkqs01kBND0cYQOAOuzfv18333yz/v3vf2vnzp365z//qe3btys4OFgXXnihbrzxRuuak23btunVV1/VtGnT1Lp1a3355Zc6//zzNXXqVL377rtat26dJGnKlCm666679O6772rfvn1yOBy644475HQ6rdDndrv1ww8/6KabbtLu3buVl5en7du364cffjil/t98803NmTNH7777rv7xj3+oZcuWuvPOO7V79+4TBq4TeeCBBzRu3Dh9+eWXevHFF7Vz50517NhRN954oy6++GI5nU59//33qqio0MyZMxUREaHS0lJ98cUXys7OrrW9F198UdOmTdOrr76quLg4paSkaNKkSbr44ot17733NtjU5J9++qlSU1P18ssv66mnnlJlZaVuu+02ZWdnex1lq8/++Tm2bNmit99+W7///e/Vrl07a1r/fv36STr5UZIXXnhB//d//6fly5fr2WefVXp6um655RZrEpH6HGX5+uuvlZeXp9dee03/+Mc/ZIzRb37zm1qn11VUVOihhx7Siy++qC+++EL//ve/1bNnT/32t7+t8zq6Y919993asGGDkpKS9NJLL2n//v2KiorSyJEj1aVLFw0bNuyk2zhWYmKi7rzzTj344IPau3evsrKyvI7+He3DDz/Uhg0b9OSTT6pHjx7asWOHbrjhhjpDTX173bFjh9atW6fExETl5eXpvPPO06RJk7Rw4UJrW/fcc482bNigLVu26MUXX1RycrJ69Oihq6++Wueee66k6mn6L7vsMm3evFkvvfSSduzYobZt2yo2NlaXX3652rVrd1rfzS9/+Us9/fTT+vbbb1VcXKyVK1ee8nYA+C7bp6qkKIry1erTp4954YUXzP79+43b7TZOp9OsX7/e3H333V7TgAcEBJg///nPZt++faa0tNSkpqbWunH2sGHDzLJly0xKSopxuVwmIyPDfPDBByY2NtbrPS+44ALz7bffGrfbfdLp3o83rb8kc/nll5tt27YZt9ttdu7caW6++eYT3jj72NcnJyebpUuXei3r2rWrefXVV01mZqZxuVxm7969ZsGCBV7Tjv/P//yP2bt3rykvL/eabv54N85++eWXTVZWlnG73Wbr1q21bmp8os9Y31sgnHvuuSYhIcG43W6TkpJi7rvvvlrT+td3/xxvWv927dp5javrxtwtWrQwCxYsMDk5OaawsNC88847pm/fvsYYY2bMmHHSz9GjRw/z4YcfmpKSEpOZmWmeeuopc/311xtjjDn//POtcZ4bZ9e1jZEjR5qvv/7alJSUmIMHD5onn3zSjB07ttatASSZ6dOnm3379hmXy2W++eabU7pxds+ePc2rr75qDh06ZEpLS82BAwfMBx98YG644YZa39Gxt1LwTGl/dD+RkZHmww8/NE6ns9atBeqqNm3amNdee826cfZrr7123Btn16fXBx54wGzatMnk5eWZkpISs2PHDjNr1iwTGBjota0BAwaYFStWmLy8PHP48GGzc+dOM3v27Fp/7hcsWGBSU1NNaWmpOXTokPnss8/M7bffXus7mDhxYp1/H47+DC1btjSvv/66ycvLM8Zw42yKamrlV/MAAADYYOjQofr+++91yy236I033jjl199777165pln1LlzZx06dOgMdAgAsBPXsAEAcJaEhobWWnbfffepsrJSX3311Sm/PiQkRNOmTdPu3bsJawDQRHENGwAAZ8mMGTMUFxentWvXqqKiQldeeaWuuuoqvfDCCzp48OBJX//OO+/op59+0vfff6+IiAj9+te/1jnnnKObb775LHQPALCL7edlUhRFUVRzqMsvv9ysX7/e5ObmmtLSUrNnzx7zl7/8xQQEBNTr9ffee69JSkoyRUVF5vDhw+a7774zkydPtv1zURRFUWeuuIYNAAAAAHwU17ABAAAAgI8isAEAAACAj2LSkbOsU6dOKioqsrsNAAAAADZzOBwnneWXwHYWderUSWlpaXa3AQAAAMBHnOw+mgS2s8hzZK1z584cZQMAAACaMYfDobS0tJPmAgKbDYqKighsAAAAAE6KSUcAAAAAwEf5TGCbOXOmjDGaP3++tWzt2rUyxnjV888/7/W6rl27auXKlSopKVFmZqbmzp2rgIAArzHx8fFKTEyU2+3Wnj17NGXKlFrvf9dddyk5OVkul0ubNm3S8OHDvdaHhIRo4cKFysnJUVFRkd5++21FRkY24DcAAAAAALXZfvfu8847z+zfv998//33Zv78+dbytWvXmhdeeMFERUVZ5XA4rPX+/v5m27Zt5tNPPzVDhw4148ePN1lZWeaxxx6zxvTo0cMUFxebv//976Z///7m7rvvNuXl5WbcuHHWmMmTJxu3222mTp1qzjnnHPPCCy+YvLw806FDB2vMokWLTGpqqrnssstMbGys+frrr82GDRtO6XM6HA5jjPH6DBRFURRFURRFNb86hWxgb6NhYWFm165dZsyYMWbt2rW1AtvRz4+t8ePHm4qKChMZGWktmzZtmikoKDBBQUFGknnyySdNUlKS1+uWL19uPv74Y+v5pk2bzIIFC6znfn5+5uDBg2bmzJlGkgkPDzelpaVm4sSJ1piYmBhjjDEjRow4EzuFoiiKoiiKoqgmXPXNBrafEvncc89p1apV+vzzz+tcf8sttyg7O1tJSUl6/PHH1aJFC2vdyJEjlZSUpKysLGvZ6tWrFRERoYEDB1pj1qxZ47XN1atXa+TIkZKkoKAgxcXFeY0xxmjNmjXWmLi4OAUHB3uN2bVrl1JTU60xdQkODpbD4fAqAAAAAKgvW2eJvOmmmxQbG1vrejGPN954Q6mpqTp06JCGDBmiOXPmKCYmRhMnTpQkRUdHKzMz0+s1nufR0dEnHBMREaHQ0FC1adNGgYGBdY7p37+/tY3S0lI5nc5aYzzvU5dZs2bpkUceOcm3AAAAAAB1sy2wdenSRc8++6zGjh2r0tLSOse89NJL1uPt27crPT1dX3zxhXr16qX9+/efrVZP2xNPPKF58+ZZzz33WgAAAACA+rDtlMi4uDhFRUVpy5YtKi8vV3l5uUaNGqV77rlH5eXl8vev3drmzZslSX369JEkZWRkKCoqymuM53lGRsYJxzidTrndbuXk5KiioqLOMUdvIyQkRBEREccdU5eysjLrnmvcew0AAADAqbItsH3++ecaNGiQhg0bZtW3336rZcuWadiwYaqqqqr1mmHDhkmS0tPTJUkJCQkaPHiwOnToYI0ZO3asnE6nduzYYY0ZM2aM13bGjh2rhIQESVJ5ebkSExO9xvj5+WnMmDHWmMTERJWVlXmN6devn7p3726NAQAAAIAzwfYZUjx19KyQvXr1Mg899JCJjY013bt3NxMmTDB79+4169atOzJjSs20/p988okZMmSIGTdunMnMzKxzWv85c+aYmJgYc+edd9Y5rb/L5TK33nqr6d+/v1m8eLHJy8vzmn1y0aJFJiUlxYwaNcrExsaajRs3mo0bN56RmWAoiqIoiqIoimra1Wim9T+6jg5sXbp0MevWrTM5OTnG5XKZ3bt3mzlz5tT6QN26dTOrVq0yJSUlJisryzz11FMmICDAa0x8fLzZsmWLcbvdZu/evWbKlCm13vvuu+82KSkpxu12m02bNpnzzz/fa31ISIhZuHChyc3NNcXFxWbFihUmKirqTO0UiqIoiqIoiqKacNU3G/jVPMBZ4HA4VFhYqPDwcK5nAwAAAJqx+mYD2+/DBgAAAACoG4ENAAAAAHwUgQ0AAAAAfBSBDQAAAAB8FIENAAAAAHwUgQ0AAAAAfBSBDQAAAAB8FIENAAAAAHwUga2ZuvPlhXrg47flaN/O7lYAAAAAHAeBrZlq372r2nXprIjIDna3AgAAAOA4CGzNVGFWjiQpIrK9zZ0AAAAAOB4CWzNVmJ0tSQrvwBE2AAAAwFcR2JopZ80RtnCOsAEAAAA+i8DWTDmzqo+wRXQgsAEAAAC+isDWTBVm1xxhi+KUSAAAAMBXEdiaKWvSEY6wAQAAAD6LwNZMOT1H2AhsAAAAgM8isDVThTXXsLVq20YBQUE2dwMAAACgLgS2Zuqws1DlpaWSpPD27WzuBgAAAEBdCGzNmDXxCFP7AwAAAD6JwNaMWROPRDJTJAAAAOCLCGzNGBOPAAAAAL6NwNaMHTnCRmADAAAAfBGBrRkrzK6eKTK8A6dEAgAAAL6IwNaMOZl0BAAAAPBpBLZmzHNKJNewAQAAAL6JwNaMOWtuns0skQAAAIBvIrA1Y54jbC0crRTcooXN3QAAAAA4FoGtGSs9fFjukhJJUniHdjZ3AwAAAOBYBLZmzrqOjdMiAQAAAJ9DYGvmCmtmioxg4hEAAADA5xDYmjlPYGOmSAAAAMD3ENiaOWdmzUyRUZwSCQAAAPgaAlsz5+QIGwAAAOCzCGzNnHVKZCSBDQAAAPA1BLZmrtBz8+wOnBIJAAAA+BoCWzPHKZEAAACA7yKwNXOF2bmSpOAWoQp1tLK5GwAAAABHI7A1cxWlpSopcEqSIrh5NgAAAOBTCGw4cvNsJh4BAAAAfAqBDdbEI+FMPAIAAAD4FAIbmHgEAAAA8FEENqgwi1MiAQAAAF9EYMORm2dzhA0AAADwKQQ2yGkdYeMaNgAAAMCXENggp2fSEU6JBAAAAHwKgQ0qzK4JbO3by8/Pz+ZuAAAAAHgQ2KCi3DxVVVUpIChQYW1a290OAAAAgBoENqiqolLFefmSmHgEAAAA8CU+E9hmzpwpY4zmz59vLQsJCdHChQuVk5OjoqIivf3224qMjPR6XdeuXbVy5UqVlJQoMzNTc+fOVUBAgNeY+Ph4JSYmyu12a8+ePZoyZUqt97/rrruUnJwsl8ulTZs2afjw4V7r69NLY+aZ2p/r2AAAAADf4ROB7bzzztO0adO0detWr+Xz58/XhAkTdOONNyo+Pl6dOnXSO++8Y6339/fXqlWrFBwcrAsvvFBTpkzR1KlT9eijj1pjevTooVWrVmnt2rUaNmyYnnnmGS1ZskTjxo2zxkyePFnz5s3T7NmzFRsbq61bt2r16tXq0KFDvXtp7DxT+zNTJAAAAOBbjJ0VFhZmdu3aZcaMGWPWrl1r5s+fbySZ8PBwU1paaiZOnGiNjYmJMcYYM2LECCPJjB8/3lRUVJjIyEhrzLRp00xBQYEJCgoyksyTTz5pkpKSvN5z+fLl5uOPP7aeb9q0ySxYsMB67ufnZw4ePGhmzpxZ717qUw6HwxhjjMPhsPU7r6sm/WWmeTopwYybfpvtvVAURVEURVFUU6/6ZgPbj7A999xzWrVqlT7//HOv5XFxcQoODtaaNWusZbt27VJqaqpGjhwpSRo5cqSSkpKUlZVljVm9erUiIiI0cOBAa8zR2/CM8WwjKChIcXFxXmOMMVqzZo01pj691CU4OFgOh8OrfFWhNbU/R9gAAAAAX2FrYLvpppsUGxurWbNm1VoXHR2t0tJSOZ1Or+WZmZmKjo62xmRmZtZa71l3ojEREREKDQ1V+/btFRgYWOeYo7dxsl7qMmvWLBUWFlqVlpZ23LF2c9acEsmkIwAAAIDvsC2wdenSRc8++6xuueUWlZaW2tXGGfXEE08oPDzcqs6dO9vd0nEx6QgAAADge2wLbHFxcYqKitKWLVtUXl6u8vJyjRo1Svfcc4/Ky8uVmZmpkJAQRUREeL0uKipKGRkZkqSMjAxFRUXVWu9Zd6IxTqdTbrdbOTk5qqioqHPM0ds4WS91KSsrU1FRkVf5KmvSEY6wAQAAAD7DtsD2+eefa9CgQRo2bJhV3377rZYtW6Zhw4bpu+++U1lZmcaMGWO9pl+/furevbsSEhIkSQkJCRo8eLDXbI5jx46V0+nUjh07rDFHb8MzxrON8vJyJSYmeo3x8/PTmDFjrDGJiYkn7aWxc2ZXX8PWql1b+R9zWwQAAAAA9rF9hhRPHT1LpCSzaNEik5KSYkaNGmViY2PNxo0bzcaNG4/MmOLvb7Zt22Y++eQTM2TIEDNu3DiTmZlpHnvsMWtMjx49THFxsZkzZ46JiYkxd955pykvLzfjxo2zxkyePNm4XC5z6623mv79+5vFixebvLw8r9knT9ZLfcqXZ4n08/Mzc7esN08nJZiIqA6290NRFEVRFEVRTblOIRvY36ynjg1sISEhZuHChSY3N9cUFxebFStWmKioKK/XdOvWzaxatcqUlJSYrKws89RTT5mAgACvMfHx8WbLli3G7XabvXv3milTptR677vvvtukpKQYt9ttNm3aZM4//3yv9fXppQF3ii310KfvmqeTEkzXQQNs74WiKIqiKIqimnLVNxv41TzAWeBwOFRYWKjw8HCfvJ7tntdfUvehg7T03pna/sVXdrcDAAAANFn1zQa234cNvoOp/QEAAADfQmCDxTNTJFP7AwAAAL6BwAaL515sEUfNugkAAADAPgQ2WAprpvaP4AgbAAAA4BMIbLA4s6oDW3gkR9gAAAAAX0Bgg8WZxaQjAAAAgC8hsMHimXQkrHWEAoODbe4GAAAAAIENFldhkcrdpZKk8A7tbO4GAAAAAIENXpw1E4+EM1MkAAAAYDsCG7xYU/tHEdgAAAAAuxHY4MW6eTYTjwAAAAC2I7DBi2dq/wgCGwAAAGA7Ahu8eE6JDOfm2QAAAIDtCGzw4uSUSAAAAMBnENjgpdBzSmQkk44AAAAAdiOwwYt1hI1TIgEAAADbEdjgxXMNW2hYmEJatrS5GwAAAKB5I7DBS5nLJVdRsSSOsgEAAAB2I7ChFu7FBgAAAPgGAhtq8ZwWGcERNgAAAMBWBDbU4syunikyvAMzRQIAAAB2IrChFs8pkUztDwAAANiLwIZaPKdEMukIAAAAYC8CG2pxem6ezaQjAAAAgK0IbKiFI2wAAACAbyCwoZYjk44Q2AAAAAA7EdhQS2F2riQpKCRELcLDbe4GAAAAaL4IbKilsrxcJfkFkqSIKGaKBAAAAOxCYEOdnJ6p/TktEgAAALANgQ11YuIRAAAAwH4ENtTJM7U/E48AAAAA9iGwoU6FnlMiI7mGDQAAALALgQ114ggbAAAAYD8CG+rEETYAAADAfgQ21IlJRwAAAAD7EdhQJ8+0/o52beXnzx8TAAAAwA78Jo46FefmqaqyUgGBgWrVprXd7QAAAADNEoENdaqqrFRRbp4kTosEAAAA7EJgw3F5Jh4J78DEIwAAAIAdCGw4Ls/EIxFRBDYAAADADgQ2HJdn4pEI7sUGAAAA2ILAhuM6ckokgQ0AAACwA4ENx1WYlS2JSUcAAAAAuxDYcFzOmsAWwaQjAAAAgC0IbDguZ82kIxxhAwAAAOxBYMNxea5hc7Rrq4DAQJu7AQAAAJofAhuO63CBUxXl5ZIkR/t2NncDAAAAND8ENhyXMebITJGcFgkAAACcdQQ2nFAh92IDAAAAbGNrYJs+fbq2bt0qp9Mpp9Opr7/+WuPHj7fWr127VsYYr3r++ee9ttG1a1etXLlSJSUlyszM1Ny5cxUQEOA1Jj4+XomJiXK73dqzZ4+mTJlSq5e77rpLycnJcrlc2rRpk4YPH+61PiQkRAsXLlROTo6Kior09ttvKzIysgG/Dd/kzPRM7c9MkQAAAMDZZmtgO3jwoO6//37FxcXpvPPO0xdffKH3339fAwYMsMa8+OKLio6OtmrGjBnWOn9/f61atUrBwcG68MILNWXKFE2dOlWPPvqoNaZHjx5atWqV1q5dq2HDhumZZ57RkiVLNG7cOGvM5MmTNW/ePM2ePVuxsbHaunWrVq9erQ5HTWc/f/58TZgwQTfeeKPi4+PVqVMnvfPOO2f4G7IfN88GAAAA7GV8qXJzc81tt91mJJm1a9ea+fPnH3fs+PHjTUVFhYmMjLSWTZs2zRQUFJigoCAjyTz55JMmKSnJ63XLly83H3/8sfV806ZNZsGCBdZzPz8/c/DgQTNz5kwjyYSHh5vS0lIzceJEa0xMTIwxxpgRI0bU+7M5HA5jjDEOh8P277m+Nfp/fmOeTkowv/zbn23vhaIoiqIoiqKaStU3G/jMNWz+/v666aabFBYWpoSEBGv5LbfcouzsbCUlJenxxx9XixYtrHUjR45UUlKSsrKyrGWrV69WRESEBg4caI1Zs2aN13utXr1aI0eOlCQFBQUpLi7Oa4wxRmvWrLHGxMXFKTg42GvMrl27lJqaao2pS3BwsBwOh1c1Np57sUUw6QgAAABw1tl+c61BgwYpISFBoaGhKi4u1vXXX6+dO3dKkt544w2lpqbq0KFDGjJkiObMmaOYmBhNnDhRkhQdHa3MzEyv7XmeR0dHn3BMRESEQkND1aZNGwUGBtY5pn///tY2SktL5XQ6a43xvE9dZs2apUceeeQUvxHfwimRAAAAgH1sD2y7du3SsGHDFBERoUmTJum1115TfHy8du7cqZdeeskat337dqWnp+uLL75Qr169tH//fhu7rp8nnnhC8+bNs547HA6lpaXZ2NGpK8zyTDpCYAMAAADONttPiSwvL9e+ffu0ZcsWPfDAA9q6davuvffeOsdu3rxZktSnTx9JUkZGhqKiorzGeJ5nZGSccIzT6ZTb7VZOTo4qKirqHHP0NkJCQhQREXHcMXUpKytTUVGRVzU2zpojbC3DwxUUGmJzNwAAAEDzYntgO5a/v79CQuoOBsOGDZMkpaenS5ISEhI0ePBgr9kcx44dK6fTqR07dlhjxowZ47WdsWPHWtfJlZeXKzEx0WuMn5+fxowZY41JTExUWVmZ15h+/fqpe/fuXtfbNUXuomKVHnZJksLbc5QNAAAAONtsmxnl8ccfN5dcconp3r27GTRokHn88cdNZWWlufzyy02vXr3MQw89ZGJjY0337t3NhAkTzN69e826deuOzJji72+2bdtmPvnkEzNkyBAzbtw4k5mZaR577DFrTI8ePUxxcbGZM2eOiYmJMXfeeacpLy8348aNs8ZMnjzZuFwuc+utt5r+/fubxYsXm7y8PK/ZJxctWmRSUlLMqFGjTGxsrNm4caPZuHHjGZkJxtfq/pVvmaeTEkzP2KG290JRFEVRFEVRTaFOIRvY1+SSJUtMcnKycbvdJjMz03z22Wfm8ssvN5JMly5dzLp160xOTo5xuVxm9+7dZs6cObU+ULdu3cyqVatMSUmJycrKMk899ZQJCAjwGhMfH2+2bNli3G632bt3r5kyZUqtXu6++26TkpJi3G632bRpkzn//PO91oeEhJiFCxea3NxcU1xcbFasWGGioqLO1E7xqbpr6SLzdFKCOffKsbb3QlEURVEURVFNoeqbDfxqHuAscDgcKiwsVHh4eKO6nu2Xf3tIw6+7Wh/9Y7E+f+k1u9sBAAAAGr36ZgOfu4YNvifnp4OSpPbdutjcCQAAANC8ENhwUlZg60pgAwAAAM4mAhtOiiNsAAAAgD0IbDip3IPVN/sO79BewS1a2NwNAAAA0HwQ2HBSrsIilRQ4JUntunayuRsAAACg+SCwoV64jg0AAAA4+whsqJfcA1zHBgAAAJxtBDbUi+cIWzsCGwAAAHDWENhQL5wSCQAAAJx9BDbUSw6nRAIAAABnHYEN9ZJ7oHpq/4ioSAUGB9vcDQAAANA8ENhQL8V5+XIXl8jf319tO3e0ux0AAACgWSCwod6s69i6dbW5EwAAAKB5ILCh3riODQAAADi7CGyotyNH2AhsAAAAwNlAYEO95VpT+3e2uRMAAACgeSCwod5yDlbPFNmOe7EBAAAAZwWBDfXmOSWyTado+QcG2NwNAAAA0PQR2FBvRdk5KnO5FRAYqDYdmdofAAAAONMIbKg3Y4xya06LZOIRAAAA4MwjsOGUMFMkAAAAcPYQ2HBKrMDGxCMAAADAGUdgwynx3Dy7HVP7AwAAAGccgQ2nJPcA17ABAAAAZwuBDack56cDkqR2XTrJz58/PgAAAMCZxG/cOCUFGVmqKC9XYHCwWkdF2t0OAAAA0KQR2HBKTFWV8g4eksRpkQAAAMCZRmDDKfPMFNmOwAYAAACcUQQ2nDJrav8uzBQJAAAAnEkENpwya2p/jrABAAAAZxSBDacstyawcQ0bAAAAcGYR2HDKrFMiuxLYAAAAgDOJwIZTln8oQ5UVFQpuEarwDu3tbgcAAABosghsOGWVFRXKT8+QxGmRAAAAwJlEYMNpyfVM7d+VmSIBAACAM4XAhtOScyBNEtexAQAAAGcSgQ2nJYeZIgEAAIAzjsCG02KdEklgAwAAAM4YAhtOC1P7AwAAAGcegQ2nJffgIVVVVamFo5XC2rS2ux0AAACgSSKw4bRUlJXJmZklievYAAAAgDOFwIbTlsPU/gAAAMAZRWDDabNmiuQ6NgAAAOCMILDhtOV67sXGKZEAAADAGUFgw2ljpkgAAADgzCKw4bRZgY0jbAAAAMAZQWDDafOcEhnWprVCHa1s7gYAAABoeghsOG1lLpcKs3MkSe2ZKRIAAABocAQ2/CxcxwYAAACcObYGtunTp2vr1q1yOp1yOp36+uuvNX78eGt9SEiIFi5cqJycHBUVFentt99WZGSk1za6du2qlStXqqSkRJmZmZo7d64CAgK8xsTHxysxMVFut1t79uzRlClTavVy1113KTk5WS6XS5s2bdLw4cO91tenl+bIM7V/O65jAwAAABqcrYHt4MGDuv/++xUXF6fzzjtPX3zxhd5//30NGDBAkjR//nxNmDBBN954o+Lj49WpUye988471uv9/f21atUqBQcH68ILL9SUKVM0depUPfroo9aYHj16aNWqVVq7dq2GDRumZ555RkuWLNG4ceOsMZMnT9a8efM0e/ZsxcbGauvWrVq9erU6dOhgjTlZL80VU/sDAAAAZ5bxpcrNzTW33XabCQ8PN6WlpWbixInWupiYGGOMMSNGjDCSzPjx401FRYWJjIy0xkybNs0UFBSYoKAgI8k8+eSTJikpyes9li9fbj7++GPr+aZNm8yCBQus535+fubgwYNm5syZRlK9eqmrgoODjcPhsKpTp07GGGMcDoft33ND1bDxl5unkxLM3a8+b3svFEVRFEVRFNVYyuFw1Csb+Mw1bP7+/rrpppsUFhamhIQExcXFKTg4WGvWrLHG7Nq1S6mpqRo5cqQkaeTIkUpKSlJWVpY1ZvXq1YqIiNDAgQOtMUdvwzPGs42goCDFxcV5jTHGaM2aNdaY+vRSl1mzZqmwsNCqtLS00/16fBZT+wMAAABnju2BbdCgQSoqKlJpaakWL16s66+/Xjt37lR0dLRKS0vldDq9xmdmZio6OlqSFB0drczMzFrrPetONCYiIkKhoaFq3769AgMD6xxz9DZO1ktdnnjiCYWHh1vVuXPTm0kx92B1CA3v0F7BLUJt7gYAAABoWgLtbmDXrl0aNmyYIiIiNGnSJL322muKj4+3u60GUVZWprKyMrvbOKNchUUqyS9QWJvWate1s9J377O7JQAAAKDJsP0IW3l5ufbt26ctW7bogQce0NatW3XvvfcqIyNDISEhioiI8BofFRWljIwMSVJGRoaioqJqrfesO9EYp9Mpt9utnJwcVVRU1Dnm6G2crJfmjKn9AQAAgDPD9sB2LH9/f4WEhCgxMVFlZWUaM2aMta5fv37q3r27EhISJEkJCQkaPHiw12yOY8eOldPp1I4dO6wxR2/DM8azjfLyciUmJnqN8fPz05gxY6wx9emlOfOcFsl1bAAAAEDDs21mlMcff9xccsklpnv37mbQoEHm8ccfN5WVlebyyy83ksyiRYtMSkqKGTVqlImNjTUbN240GzduPDJjir+/2bZtm/nkk0/MkCFDzLhx40xmZqZ57LHHrDE9evQwxcXFZs6cOSYmJsbceeedpry83IwbN84aM3nyZONyucytt95q+vfvbxYvXmzy8vK8Zp88WS/1qfrOBNPY6oq7bjdPJyWYSQ/PtL0XiqIoiqIoimoMdQrZwL4mlyxZYpKTk43b7TaZmZnms88+s8KaJBMSEmIWLlxocnNzTXFxsVmxYoWJiory2ka3bt3MqlWrTElJicnKyjJPPfWUCQgI8BoTHx9vtmzZYtxut9m7d6+ZMmVKrV7uvvtuk5KSYtxut9m0aZM5//zzvdbXp5cG3CmNquKuGW+eTkow05cssL0XiqIoiqIoimoMVd9s4FfzAGeBw+FQYWGhwsPDVVRUZHc7Dab70EG65/WXlHcoXY9dcYPd7QAAAAA+r77ZwOeuYUPj45l0pHV0lAKDg23uBgAAAGg6CGz42UryC+QqKpa/v7/adu5odzsAAABAk0FgQ4PIOVAztX+3rjZ3AgAAADQdBDY0iNwDTO0PAAAANDQCGxqEdfNsAhsAAADQYAhsaBC5NYGtXZfONncCAAAANB0ENjSII9ewcYQNAAAAaCgENjQIzymRbTpFyz8wwOZuAAAAgKaBwIYGUZidozKXWwGBgWrTkan9AQAAgIZAYEODyT3ITJEAAABAQyKwocEwUyQAAADQsAhsaDCewNauKzNFAgAAAA2BwIYGY80U2ZUjbAAAAEBDILChweRySiQAAADQoAhsaDDWKZFdOsnPnz9aAAAAwM/Fb9VoMAWZWaooK1NgcLBaR0Xa3Q4AAADQ6BHY0GBMVZXy0tIlcVokAAAA0BAIbGhQ1mmRBDYAAADgZyOwoUF5AluH7l1t7gQAAABo/AhsaFDpu/dKkjrH9LO5EwAAAKDxI7ChQaXt2i1J6tS/r82dAAAAAI0fgQ0NKmNvsirLKxTWOkKto6PsbgcAAABo1AhsaFCV5eXK3J8sSerMUTYAAADgZyGwocGl/Vh9WmTn/lzHBgAAAPwcBDY0uLQf90iSOhHYAAAAgJ+FwIYGxxE2AAAAoGEQ2NDgDu2qPsLWtnNHtQh32NwNAAAA0HgR2NDg3EXFyj2YJknqFMPEIwAAAMDpIrDhjPBcx8ZpkQAAAMDpI7DhjOA6NgAAAODnI7DhjDhkzRTJKZEAAADA6SKw4YxI+3GXJCmqVw8FBgfb3A0AAADQOBHYcEY4M7NVkl+ggMBARffpaXc7AAAAQKNEYMMZw3VsAAAAwM9DYMMZk2Zdx0ZgAwAAAE4HgQ1nDEfYAAAAgJ+HwIYz5lBNYOsU00d+fn42dwMAAAA0PgQ2nDFZKT+pzOVWSMuWateti93tAAAAAI0OgQ1njKmqUvqefZI4LRIAAAA4HQQ2nFFcxwYAAACcPgIbzqhD1kyRfW3uBAAAAGh8CGw4o9J+3CVJ6hxDYAMAAABOFYENZ1T6nn2qqqxUeIf2crRra3c7AAAAQKNCYMMZVe4uVXbqAUncQBsAAAA4VQQ2nHFMPAIAAACcHgIbzrhDVmDjOjYAAADgVBDYcMZxhA0AAAA4PQQ2nHFpNVP7t+vWRSEtW9rcDQAAANB42BrY7r//fn3zzTcqLCxUZmam3n33XfXr530UZu3atTLGeNXzzz/vNaZr165auXKlSkpKlJmZqblz5yogIMBrTHx8vBITE+V2u7Vnzx5NmTKlVj933XWXkpOT5XK5tGnTJg0fPtxrfUhIiBYuXKicnBwVFRXp7bffVmRkZAN9G01XSX6BCjKz5O/vr479+tjdDgAAANBo2BrY4uPj9dxzz+mCCy7Q2LFjFRQUpE8//VQtjzkK8+KLLyo6OtqqGTNmWOv8/f21atUqBQcH68ILL9SUKVM0depUPfroo9aYHj16aNWqVVq7dq2GDRumZ555RkuWLNG4ceOsMZMnT9a8efM0e/ZsxcbGauvWrVq9erU6dOhgjZk/f74mTJigG2+8UfHx8erUqZPeeeedM/gNNR2eG2hzHRsAAABwaoyvVPv27Y0xxlxyySXWsrVr15r58+cf9zXjx483FRUVJjIy0lo2bdo0U1BQYIKCgowk8+STT5qkpCSv1y1fvtx8/PHH1vNNmzaZBQsWWM/9/PzMwYMHzcyZM40kEx4ebkpLS83EiROtMTExMcYYY0aMGFGvz+dwOIwxxjgcDtu/67Nd4//vf83TSQlm8iOzbO+FoiiKoiiKouyu+mYDn7qGLSIiQpKUl5fntfyWW25Rdna2kpKS9Pjjj6tFixbWupEjRyopKUlZWVnWstWrVysiIkIDBw60xqxZs8Zrm6tXr9bIkSMlSUFBQYqLi/MaY4zRmjVrrDFxcXEKDg72GrNr1y6lpqZaY44VHBwsh8PhVc2VZ+KRThxhAwAAAOot0O4GPPz8/PTMM89ow4YN+uGHH6zlb7zxhlJTU3Xo0CENGTJEc+bMUUxMjCZOnChJio6OVmZmpte2PM+jo6NPOCYiIkKhoaFq06aNAgMD6xzTv39/axulpaVyOp21xnje51izZs3SI488corfRNPkCWwd+/aWf2CAqioqbe4IAAAA8H0+E9iee+45DRo0SBdffLHX8pdeesl6vH37dqWnp+uLL75Qr169tH///rPd5il54oknNG/ePOu5w+FQWlqajR3ZJz8tXa6iYrVwtFJkzx7K2LPP7pYAAAAAn+cTp0QuWLBA11xzjS677LKTBprNmzdLkvr0qZ5tMCMjQ1FRUV5jPM8zMjJOOMbpdMrtdisnJ0cVFRV1jjl6GyEhIdZpm3WNOVZZWZmKioq8qrkyxujQLs/EI9yPDQAAAKgP2wPbggULdP3112v06NFKSUk56fhhw4ZJktLT0yVJCQkJGjx4sNdsjmPHjpXT6dSOHTusMWPGjPHaztixY5WQkCBJKi8vV2JiotcYPz8/jRkzxhqTmJiosrIyrzH9+vVT9+7drTE4sSM30OY6NgAAAKC+bJsZ5bnnnjP5+fnm0ksvNVFRUVaFhoYaSaZXr17moYceMrGxsaZ79+5mwoQJZu/evWbdunVHZk3x9zfbtm0zn3zyiRkyZIgZN26cyczMNI899pg1pkePHqa4uNjMmTPHxMTEmDvvvNOUl5ebcePGWWMmT55sXC6XufXWW03//v3N4sWLTV5entfsk4sWLTIpKSlm1KhRJjY21mzcuNFs3LixwWeCaao1/LqrzNNJCebOlxfa3gtFURRFURRF2VmnkA3sa/J4pkyZYiSZLl26mHXr1pmcnBzjcrnM7t27zZw5c2p9qG7duplVq1aZkpISk5WVZZ566ikTEBDgNSY+Pt5s2bLFuN1us3fvXus9jq67777bpKSkGLfbbTZt2mTOP/98r/UhISFm4cKFJjc31xQXF5sVK1aYqKioM7FTmmR1iulrnk5KMH/duNr2XiiKoiiKoijKzqpvNvCreYCzwOFwqLCwUOHh4c3yeraAwEA9/s0XCgwK0t+uuF75h+q+9g8AAABo6uqbDWy/hg3NR2VFhTL3Jkti4hEAAACgPghsOKuOTDxCYAMAAABOhsCGs8oT2DoxUyQAAABwUqcV2H7zm98oODi41vKgoCD95je/+dlNoeniCBsAAABQf6cV2JYuXVrrBtJS9YVzS5cu/dlNoeny3Dy7TcdotYwIt7kbAAAAwLedVmDz8/OTMbUnl+zSpYucTufPbgpNV2nJYeX8dFASR9kAAACAkwk8lcFbtmyRMUbGGH3++eeqqKiw1gUEBKhnz5765JNPGrxJNC1pP+5W+25d1Cmmr/Zs/s7udgAAAACfdUqB7b333pMkDRs2TKtXr1ZxcbG1rqysTCkpKVqxYkWDNoimJ+3H3Ro6brQ6n8MRNgAAAOBETimwPfroo5KklJQUvfnmmyorKzsjTaFpO/Rj9XVsnWKYKRIAAAA4kdO6hu2LL75Qhw4drOfDhw/X/PnzdccddzRYY2i6PDNFRvbsrsCQEJu7AQAAAHzXaQW2N954Q5dddpkkKSoqSmvWrNH555+vxx57TH/+858btEE0PYXZOSrKzVNAYKA69ulldzsAAACAzzqtwDZo0CB98803kqTJkycrKSlJF110kW655RZNnTq1IftDE3XIcz82rmMDAAAAjuu0AltQUJBKS0slSZdffrk++OADSdKPP/6ojh07Nlx3aLLSdnEdGwAAAHAypxXYfvjhB02fPl0XX3yxxo4da03l36lTJ+Xm5jZog2ia0nZyhA0AAAA4mdMKbDNnztS0adO0bt06LV++XNu2bZMkXXvttdapksCJHKo5wtaxbx/5+Z/WH0MAAACgyTulaf09vvzyS7Vv317h4eEqKCiwlr/44os6fPhwQ/WGJiw79YBKD7sU0rKFOnTvqqzkVLtbAgAAAHzOaR/aqKqqUmBgoC666CJddNFFat++vVJTU5Wdnd2Q/aGJMlVVSt+zVxLXsQEAAADHc1qBrWXLlnr55ZeVnp6ur776Sl999ZUOHTqkJUuWqEWLFg3dI5oozw20uY4NAAAAqNtpBbZ58+YpPj5eEyZMUOvWrdW6dWtdd911io+P19NPP93QPaKJ8txAu+uAc2zuBAAAAPBNpxXYJk6cqP/5n//RJ598oqKiIhUVFenjjz/WHXfcoUmTJjV0j2iikv9bPVlN96GDFBAUZHM3AAAAgO857VMiMzMzay3PyspSy5Ytf3ZTaB4y9yWrKDdPwS1C1W3wALvbAQAAAHzOaQW2hIQEzZ49WyEhIday0NBQPfzww0pISGiw5tD07ft2iySp9/BYmzsBAAAAfM9pBbb77rtPF110kQ4ePKg1a9ZozZo1OnDggC666CLde++9Dd0jmrC9NYGtD4ENAAAAqOW07sO2fft29e3bV7fccov69+8vSVq+fLmWLVsmt9vdoA2iafMcYesxbLACg4NVUVZmc0cAAACA7zitwHb//fcrMzNTS5Ys8Vr+29/+Vh06dNDcuXMbpDk0fVnJqSrMzlF4h/bqNmSg9n/3X7tbAgAAAHzGaZ0SOW3aNP3444+1lv/www+aPn36z24Kzcs+TosEAAAA6nRagS06Olrp6em1lmdnZ6tjx44/uyk0L9Z1bOfH2dwJAAAA4FtOK7B5Jhg51kUXXaRDhw797KbQvOz9JlGS1H3IQAUeNfMoAAAA0Nyd1jVsL730kp555hkFBQXpiy++kCSNGTNGc+fO1dNPP92gDaLpy/npoJyZ2YqI6qAeQwdZAQ4AAABo7k4rsD311FNq166dFi1apODgYEmS2+3WnDlz9OSTTzZog2ge9n6bqLhrxqvP+XEENgAAAKDGaZ0SKVXPFNmhQwddcMEFGjp0qNq2bau//vWvDdkbmpG939TcQPu8c23uBAAAAPAdp3WEzaOkpETfffddQ/WCZswzU2S3IQMVFBqicnepzR0BAAAA9jvtI2xAQ8o9mKb89AwFBgWp57lD7G4HAAAA8AkENviMI6dFcj82AAAAQCKwwYfs+7Z6shHuxwYAAABUI7DBZ3huoN114DkKbtHC5m4AAAAA+xHY4DPyD2Uo9+AhBQQFch0bAAAAIAIbfIxntsg+53MdGwAAAEBgg0/xnBbZezjXsQEAAAAENviUfd9UTzzSZUCMQsJa2twNAAAAYC8CG3xKQWaWcn46qIDAQPWMHWp3OwAAAICtCGzwOdZ1bJwWCQAAgGaOwAafs7fmfmy9h59rcycAAACAvQhs8Dl7v/2vJKnLOTEKbRVmczcAAACAfQhs8DmFWdnKTvlJ/gEB6hXHUTYAAAA0XwQ2+KQj0/sT2AAAANB8Edjgk/bWTO/PxCMAAABozghs8En7vqu+jq1T/75qER5uczcAAACAPQhs8ElFObnK3J8if39/9YrjfmwAAABonmwNbPfff7+++eYbFRYWKjMzU++++6769evnNSYkJEQLFy5UTk6OioqK9PbbbysyMtJrTNeuXbVy5UqVlJQoMzNTc+fOVUBAgNeY+Ph4JSYmyu12a8+ePZoyZUqtfu666y4lJyfL5XJp06ZNGj58+Cn3gobDaZEAAACAZOyqjz/+2EyZMsUMGDDADBkyxKxcudKkpKSYli1bWmMWLVpkUlNTzWWXXWZiY2PN119/bTZs2GCt9/f3N9u2bTOffvqpGTp0qBk/frzJysoyjz32mDWmR48epri42Pz97383/fv3N3fffbcpLy8348aNs8ZMnjzZuN1uM3XqVHPOOeeYF154weTl5ZkOHTrUu5eTlcPhMMYY43A4bPvOG1MNvWKMeTopwfzx7X/a3gtFURRFURRFNWSdQjawv1lPtW/f3hhjzCWXXGIkmfDwcFNaWmomTpxojYmJiTHGGDNixAgjyYwfP95UVFSYyMhIa8y0adNMQUGBCQoKMpLMk08+aZKSkrzea/ny5ebjjz+2nm/atMksWLDAeu7n52cOHjxoZs6cWe9eGnCnUJJp1baNeTopwTydlGBaRoTb3g9FURRFURRFNVTVNxv41DVsERERkqS8vDxJUlxcnIKDg7VmzRprzK5du5SamqqRI0dKkkaOHKmkpCRlZWVZY1avXq2IiAgNHDjQGnP0NjxjPNsICgpSXFyc1xhjjNasWWONqU8vxwoODpbD4fAq1F9xXr7S9+yTJPU+j+n9AQAA0Pz4TGDz8/PTM888ow0bNuiHH36QJEVHR6u0tFROp9NrbGZmpqKjo60xmZmZtdZ71p1oTEREhEJDQ9W+fXsFBgbWOebobZysl2PNmjVLhYWFVqWlpdX7+0A1z2yRfc7nOjYAAAA0Pz4T2J577jkNGjRIv/zlL+1upcE88cQTCg8Pt6pz5852t9ToeCYe6T081uZOAAAAgLPPJwLbggULdM011+iyyy7zOgqVkZGhkJAQ61RJj6ioKGVkZFhjoqKiaq33rDvRGKfTKbfbrZycHFVUVNQ55uhtnKyXY5WVlamoqMircGr21xxh69i3t8LatLa3GQAAAOAssz2wLViwQNdff71Gjx6tlJQUr3WJiYkqKyvTmDFjrGX9+vVT9+7dlZCQIElKSEjQ4MGD1aFDB2vM2LFj5XQ6tWPHDmvM0dvwjPFso7y8XImJiV5j/Pz8NGbMGGtMfXpBwyspcOrQ7r2SOMoGAACA5sm2mVGee+45k5+fby699FITFRVlVWhoqDVm0aJFJiUlxYwaNcrExsaajRs3mo0bNx6ZNaVmWv9PPvnEDBkyxIwbN85kZmbWOa3/nDlzTExMjLnzzjvrnNbf5XKZW2+91fTv398sXrzY5OXlec0+ebJeTlbMEnl6dd3M+8zTSQnmhgf/n+29UBRFURRFUVRDVKOY1v94pkyZYo0JCQkxCxcuNLm5uaa4uNisWLHCREVFeW2nW7duZtWqVaakpMRkZWWZp556ygQEBHiNiY+PN1u2bDFut9vs3bvX6z08dffdd5uUlBTjdrvNpk2bzPnnn++1vj69NNBOoY6qQaMvNU8nJZg/vfeG7b1QFEVRFEVRVENUfbOBX80DnAUOh0OFhYUKDw/nerZT0CI8XI+u/1j+/v56ZNTVKsrNs7slAAAA4Gepbzaw/Ro24GRchYVK31VzHRv3YwMAAEAzQmBDo7D325rp/bkfGwAAAJoRAhsahX3fbpEk9R1xns2dAAAAAGcPgQ2Nwt5vt6i8tFQdundVdN/edrcDAAAAnBUENjQKpSWHtevrzZKkoeNG29wNAAAAcHYQ2NBobP30C0kENgAAADQfBDY0Gj+sXa/y0lJF9eqh6D697G4HAAAAOOMIbGg0OC0SAAAAzQ2BDY2K57TIIQQ2AAAANAMENjQqO9ZtUEVZmaJ791RU7552twMAAACcUQQ2NCru4hLt2lh9WuSwK8bY3A0AAABwZhHY0OhwWiQAAACaCwIbGp0f1q3ntEgAAAA0CwQ2NDru4hLt+vobScwWCQAAgKaNwIZGiZtoAwAAoDkgsKFR+mHdelWUlyu6Ty9F9ephdzsAAADAGUFgQ6PkLiq2ZovkKBsAAACaKgIbGi1miwQAAEBTR2BDo+U5LbJj396cFgkAAIAmicCGRstdVKzdzBYJAACAJozAhkaN0yIBAADQlBHY0KhtX/uVdVpkZM/udrcDAAAANCgCGxo1d1GxdifUnBZ5xRibuwEAAAAaFoENjd42bqINAACAJorAhkZv+9r1nBYJAACAJonAhkbPVVikPZu+lcTkIwAAAGhaCGxoErau/lwSp0UCAACgaSGwoUnwnBbZqV8fTosEAABAk0FgQ5PAaZEAAABoighsaDK2MlskAAAAmhgCG5qM7V+sV2V5hTr166MOPbrZ3Q4AAADwsxHY0GS4Cgu1e3P1aZEcZQMAAEBTQGBDk7JtNadFAgAAoOkgsKFJSfriq+rTImP6qn33rna3AwAAAPwsBDY0Ka7CQu3Z/J0kjrIBAACg8SOwoclhtkgAAAA0FQQ2NDnbv/hSleUV6ty/nzrF9LW7HQAAAOC0EdjQ5Bx2FmrbmrWSpEtumWxzNwAAAMDpI7ChSdqw7D+SpHOvGquwNq3tbQYAAAA4TQQ2NEkpW5P00/YdCgoJ0QUTr7O7HQAAAOC0ENjQZHmOsl34yxvkHxhgczcAAADAqSOwocn6fvXnKszJVeuoSA0ZM8rudgAAAIBTRmBDk1VZXq6Et96VJF3y65ts7gYAAAA4dQQ2NGkJb72rivJy9Rg2WF0HnmN3OwAAAMApIbChSSvKzdP3n6yRJF18y402dwMAAACcGgIbmjzP5CPDxl8uR7u2NncDAAAA1B+BDU3egR92KuX7JAUGBWnk5OvtbgcAAACoNwIbmoX1r/9bkjRy8vUKCAqyuRsAAACgfghsaBa2fb5OBZlZCm/fTsOuGGN3OwAAAEC92BrYLrnkEn3wwQdKS0uTMUbXXXed1/qlS5fKGONVH3/8sdeYNm3a6PXXX5fT6VR+fr6WLFmisLAwrzGDBw/WV199JZfLpZ9++kl/+tOfavUyadIk7dy5Uy6XS9u2bdOVV15Za8zs2bN16NAhHT58WJ999pn69OnTAN8Czoaqikp9/eY7kqRLfj3Z5m4AAACA+rE1sIWFhWnr1q26++67jzvm448/VnR0tFW/+tWvvNYvW7ZMAwcO1NixY3XNNdfo0ksv1Ysvvmitdzgc+vTTT5Wamqq4uDj96U9/0iOPPKI77rjDGjNy5EgtX75cL7/8ss4991y99957eu+99zRw4EBrzIwZM3TPPfdo+vTpGjFihEpKSrR69WqFhIQ04DeCM2nTivdVXlqqrgPPUY+hg+1uBwAAAKgX4wtljDHXXXed17KlS5ead99997iv6d+/vzHGmLi4OGvZFVdcYSorK03Hjh2NJDN9+nSTm5trgoKCrDFPPPGE2blzp/X8zTffNB9++KHXthMSEszzzz9vPT906JD54x//aD0PDw83LpfL3HTTTfX+jA6HwxhjjMPhsP37bq5106MPmqeTEsyv5z5qey8URVEURVFU8636ZgOfv4Zt1KhRyszM1I8//qhFixapbdsj07KPHDlS+fn5SkxMtJatWbNGVVVVGjFihDXmq6++Unl5uTVm9erV6t+/v1q3bm2NWbNmjdf7rl69WiNHjpQk9ezZUx07dvQaU1hYqM2bN1tj6hIcHCyHw+FVsNf6ZW9JkoaMvUwRUR1s7gYAAAA4MZ8ObJ988oluvfVWjRkzRjNnzlR8fLw+/vhj+ftXtx0dHa2srCyv11RWViovL0/R0dHWmMzMTK8xnucnG3P0+qNfV9eYusyaNUuFhYVWpaWlndLnR8M7tGuP9n33XwUEBurCyTfY3Q4AAABwQj4d2P7973/rww8/1Pbt2/X+++/rmmuu0fnnn69Ro0bZ3Vq9PPHEEwoPD7eqc+fOdrcEHTXF/42/UCDXIAIAAMCH+XRgO1ZycrKys7Ot2RkzMjIUGRnpNSYgIEBt27ZVRkaGNSYqKsprjOf5ycYcvf7o19U1pi5lZWUqKiryKtjvh3UblHcoXWFtWiv2yrF2twMAAAAcV6MKbJ07d1a7du2Unp4uSUpISFCbNm0UGxtrjRk9erT8/f21efNma8yll16qwMBAa8zYsWP1448/qqCgwBozZoz3vbnGjh2rhIQESdVBMT093WuMw+HQiBEjrDFoPKoqK7Vx+QpJTPEPAAAA32fbzChhYWFm6NChZujQocYYY+677z4zdOhQ07VrVxMWFmbmzp1rRowYYbp3725Gjx5tvvvuO7Nr1y4THBxsbeOjjz4yiYmJZvjw4ebCCy80u3btMsuWLbPWh4eHm/T0dPPaa6+ZAQMGmMmTJ5vi4mJzxx13WGNGjhxpysrKzB/+8AcTExNjHn74YVNaWmoGDhxojZkxY4bJy8szEyZMMIMGDTLvvvuu2bdvnwkJCWnwmWCoM18twsPNE9+sNU8nJZhe551rez8URVEURVFU86pTyAb2NRkfH2/qsnTpUhMaGmo++eQTk5mZaUpLS01ycrJ54YUXTGRkpNc22rRpY5YtW2YKCwtNQUGBefnll01YWJjXmMGDB5uvvvrKuFwuc+DAATNjxoxavUyaNMn8+OOPxu12m6SkJHPllVfWGjN79myTnp5uXC6X+eyzz0zfvn3P1E6hzkJN/PMM83RSgpky/wnbe6EoiqIoiqKaV9U3G/jVPMBZ4HA4VFhYqPDwcK5n8wFRvXtqxntvqKqyUo9fNUn5h45/PSIAAADQkOqbDRrVNWxAQ8rcl6zdCd/IPyBAF/1ykt3tAAAAALUQ2NCsrV/2H0nSiIkTFNwi1OZuAAAAAG8ENjRrO9d/rZyfDqpleLguvpkZIwEAAOBbCGxo1kxVlT59/mVJ0pjbb1VYm9b2NgQAAAAchcCGZm/LqtU6uGOXQluFadz02+xuBwAAALAQ2NDsGWO0ct5CSdLIG69X++5dbe4IAAAAqEZgAyTt2fyddny1UQFBgbr6vrvsbgcAAACQRGADLCvnPaeqykoNuXyUep47xO52AAAAAAIb4JG5L1nfvLtSknTNH//P5m4AAAAAAhvg5ZPnXlLpYZd6DB2sIeNG290OAAAAmjkCG3CUopxcrXt1mSTp6vvuVEBgoM0dAQAAoDkjsAHHWPfqGyrMzlH7rl104S8n2t0OAAAAmjECG3CMMpdLqxctkSSNnfZbhTpa2dwRAAAAmisCG1CHb95dqYy9+xXWOkKX3z7F7nYAAADQTBHYgDpUVVZq5bznJEkX33Kj2nSMtrkjAAAANEcENuA4dq7/Wns2f6egkBBdec80u9sBAABAM0RgA05g5byFkqS4a8ary4D+NncDAACA5obABpzAwR279N2HH0uSJnAzbQAAAJxlBDbgJD5Z8KLKS0vV5/w4nXPpRXa3AwAAgGaEwAacRH56htYve0uSdM0f7pZ/QIDNHQEAAKC5ILAB9fD5kn+qJL9A0b176vzrr7G7HQAAADQTBDagHtxFxfp08SuSpCvuvkMhLVva3BEAAACaAwIbUE8Jb72r7NQDCm/fTlf83x12twMAAIBmgMAG1FNlRYXefWKeJCn+N79U3xHn2dwRAAAAmjoCG3AKdm3cpI1vrpAk/fJvD6lFuMPmjgAAANCUEdiAU7Ry3kJlp/yk1tFRuuGBP9rdDgAAAJowAhtwispcbr3xwGxVVlQo9uorNGz85Xa3BAAAgCaKwAachp+SdmjNi69Kkib++U8Kj+xgb0MAAABokghswGla89Kr+ilph1qGh+uXf31Qfn5+drcEAACAJobABpymqopKvfHAbJW53Iq5cIQu+tVEu1sCAABAE0NgA36G7JSf9MHf/yFJuub3/6eoXj3sbQgAAABNCoEN+JkS3npXOzckKCg0RL964mEFBAba3RIAAACaCAIb0AD+/efHVFLgVNcB/TX2ztvsbgcAAABNBIENaABFObn6z+wnJUlj/udW9Rg62OaOAAAA0BQQ2IAGkrRmnb59/yP5BwToV0/8RcEtWtjdEgAAABo5AhvQgN57cp7yDqWrfdcuunbGPXa3AwAAgEaOwAY0IHdxiZY/+FdVVVVp5KRfaOCoi+1uCQAAAI0YgQ1oYPu/+6++fPUNSdKNj8xSq7ZtbO4IAAAAjRWBDTgDPl74og7t3itHu7b69dxHmeofAAAAp4XABpwBleXlWjbzYblLStR3xHm68ZH77W4JAAAAjRCBDThDMvbu1z//+JAqKyo0/Lqrdfm039rdEgAAABoZAhtwBu3auEnvPPZ3SdKV//e/ir3mCps7AgAAQGNCYAPOsE1vv68vXvmXJOmmRx9Ur/POtbkjAAAANBYENuAs+OiZ5/X96s8VGBSk3z77pCJ7dre7JQAAADQCBDbgLDDGaPmDf1Xyf7epZXi4bl/0NNP9AwAA4KQIbMBZUlFaqqX3zFDOTwfVrktn3faPuQoKDbG7LQAAAPgwAhtwFpUUOPXSXX9QSYFT3YcO0s2PPyw/Pz+72wIAAICPIrABZ1lO6gEtvWeGKsrKNGTsZbrmD/9nd0sAAADwUQQ2wAbJ/92mNx/6myRp1NSbdeFNN9jcEQAAAHyRrYHtkksu0QcffKC0tDQZY3TdddfVGjN79mwdOnRIhw8f1meffaY+ffp4rW/Tpo1ef/11OZ1O5efna8mSJQoLC/MaM3jwYH311VdyuVz66aef9Kc//anW+0yaNEk7d+6Uy+XStm3bdOWVV55yL8Cp+O/Hn+mjZxdLkq6f9Qedc8mFNncEAAAAX2NrYAsLC9PWrVt1991317l+xowZuueeezR9+nSNGDFCJSUlWr16tUJCjkzUsGzZMg0cOFBjx47VNddco0svvVQvvviitd7hcOjTTz9Vamqq4uLi9Kc//UmPPPKI7rjjDmvMyJEjtXz5cr388ss699xz9d577+m9997TwIEDT6kX4FR9vuQ1bV7xgfwDAvSbv/9Vnc/pZ3dLAAAA8DHGF8oYY6677jqvZYcOHTJ//OMfrefh4eHG5XKZm266yUgy/fv3N8YYExcXZ4254oorTGVlpenYsaORZKZPn25yc3NNUFCQNeaJJ54wO3futJ6/+eab5sMPP/R674SEBPP888/Xu5f6lMPhMMYY43A4bP++Kd8p/8AA878vPGOeTkowj371sekyIMb2niiKoiiKoqgzW/XNBj57DVvPnj3VsWNHrVmzxlpWWFiozZs3a+TIkZKqj4zl5+crMTHRGrNmzRpVVVVpxIgR1pivvvpK5eXl1pjVq1erf//+at26tTXm6PfxjPG8T316qUtwcLAcDodXAceqqqjUP//4oFK3/aCwNq1158vPqVfcMLvbAgAAgA/w2cAWHR0tScrMzPRanpmZaa2Ljo5WVlaW1/rKykrl5eV5jalrG0e/x/HGHL3+ZL3UZdasWSosLLQqLS3tJJ8azZW7uEQv3HGP9n6TqNBWYfrfxc+o/8UX2N0WAAAAbOazga0peOKJJxQeHm5V586d7W4JPqz08GG9dNcftePLjQoKDdFv/zFXQ8aNtrstAAAA2MhnA1tGRoYkKSoqymt5VFSUtS4jI0ORkZFe6wMCAtS2bVuvMXVt4+j3ON6Yo9efrJe6lJWVqaioyKuAE6koLdXS+2bqvx99qsCgIP1m7qM6/xfX2N0WAAAAbOKzgS05OVnp6ekaM2aMtczhcGjEiBFKSEiQJCUkJKhNmzaKjY21xowePVr+/v7avHmzNebSSy9VYGCgNWbs2LH68ccfVVBQYI05+n08YzzvU59egIZSVVGpZbNmK+Ht9+QfEKCb/vqgLvn1TXa3BQAAAJvYNjNKWFiYGTp0qBk6dKgxxpj77rvPDB061HTt2tVIMjNmzDB5eXlmwoQJZtCgQebdd981+/btMyEhIdY2PvroI5OYmGiGDx9uLrzwQrNr1y6zbNkya314eLhJT083r732mhkwYICZPHmyKS4uNnfccYc1ZuTIkaasrMz84Q9/MDExMebhhx82paWlZuDAgdaY+vRysmKWSOpU65o//J95OinBPJ2UYMZOv832fiiKoiiKoqiGqVPIBvY1GR8fb+qydOlSa8zs2bNNenq6cblc5rPPPjN9+/b12kabNm3MsmXLTGFhoSkoKDAvv/yyCQsL8xozePBg89VXXxmXy2UOHDhgZsyYUauXSZMmmR9//NG43W6TlJRkrrzyylpjTtZLA+4UirLq8v+daoW2Cf/vd7b3Q1EURVEURf38qm828Kt5gLPA4XCosLBQ4eHhXM+GU3LxzTfq+ll/kCRtevt9vf3XuTJVVTZ3BQAAgNNV32zgs9ewAThiwxv/0ZsP/VVVlZW6YNJ1uuXJRxRw1HWZAAAAaJoIbEAj8e37H+lff/qzKsrLde6VY3XbgqfUIpybsQMAADRlBDagEdn22Vq98n9/UpnLrf4XX6D73nxFnWL62t0WAAAAzhACG9DI7Pp6sxZOmabcg4fUvmsX3fP6Szrv2qvsbgsAAABnAIENaITSdu7W/Jt+q53rv1ZQaIh+9difNfHPMxQQFGR3awAAAGhABDagkXIVFurlu/+fVj/3kqqqqnTh5Ov1f68tVuvoKLtbAwAAQAMhsAGNmDFGny5+RUvu+qMOOwvVbfAA/eGtV9Vv5HC7WwMAAEADILABTcCujZs0b/IUHdjxo8LatNYdi5/RmDumyM/Pz+7WAAAA8DMQ2IAmIv9Qhhb+Zpo2r/hA/v7+uuqe6frts3MU6mhld2sAAAA4TQQ2oAmpKCvTW488oX//5XGVl5Zq4GWX6Pf/XqqO/frY3RoAAABOA4ENaIK+efdDLbz1yNT/976xRJfd9mv5BwTY3RoAAABOAYENaKIO7til+Tf9Vju+2qigkBBd8/u7dc+ylzjaBgAA0Ij4STJ2N9FcOBwOFRYWKjw8XEVFRXa3g2Zk+HVX6doZ96pleLgqyyv0xSv/0mcvLFVlebndrQEAADRL9c0GHGEDmoFv3/9Ic6+7WdvWrFNAUKDGTvut/vCf19RtyEC7WwMAAMAJcITtLOIIG3zB4MtH6YYH/5/C27dTVVWV1i97S58seEFlLrfdrQEAADQbHGEDUKekNes097qb9e37H8nf31/xv/ml/t87r6vviPPsbg0AAADH4AjbWcQRNviamIsu0KS/zFDbTh0lSZvefl8fzlsod1GxzZ0BAAA0bRxhA3BSuzZu0t+v/7U2LH9bknTBpOs04903dN61V8nPz8/m7gAAAMARtrOII2zwZT1jh+qm2Q+oQ49ukqS0nbv14byF2rPpW5s7AwAAaHrqmw0IbGcRgQ2+LjA4WJfccqPG3D5FLcIdkqSdGxK0ct5zytizz+buAAAAmg4Cmw8isKGxaBkRrrHTbtOFv7xBgUFBqqqs1Lfvf6RPnntJhVnZdrcHAADQ6BHYfBCBDY1Nuy6dddV9d2rYFWMkSWUut77853KtfeV1lR4+bHN3AAAAjReBzQcR2NBYdRsyUNf+8XfqGTtUklSUm6fVi5Zo8zsfqKqi0ubuAAAAGh8Cmw8isKGxGzQ6Xtf8/i5rYpKs5FR9uvgVbV39uaoqCW4AAAD1RWDzQQQ2NAX+gQEaOekXGnfn/6hV2zaSpJwDB7Vu6Rv69v1Vqigrs7lDAAAA30dg80EENjQlIWEtdcktk3XJLZOt4FaYk6uv/vWmvv73Oyot4Ro3AACA4yGw+SACG5qioNAQjbhhguKn3Ky2nTpKklyFRdr473e0/vV/qzgv3+YOAQAAfA+BzQcR2NCU+QcG6Nwrx2n0//xG0b17SpLK3aXa/O6HWvfqMuUfyrC5QwAAAN9BYPNBBDY0B35+fhp42SUa/T+3qvuQgZKkyooKff/JGn352nKl/bjb5g4BAADsR2DzQQQ2NDe9h8dqzO23KubCEday1G0/KOGtd/T96s9V7i61sTsAAAD7ENh8EIENzVWXATEaNeVmDR57mQKDgiRJhwsL9d37HyvhP+8qKznV5g4BAADOLgKbDyKwoblr1baNzr/+Gl0w6Rdq16WTtXzvN4lKeOtdJX3+pSorKmzsEAAA4OwgsPkgAhtQzc/PT/0uHKELJ/9CA+Ivln9AgCSpKDdPm9/5UJvefo9JSgAAQJNGYPNBBDagttZRkRox8VqNmHitIiI7SJKqqqq0J+EbJa76VNs//1Klh7mnGwAAaFoIbD6IwAYcn39ggAZcerEuvOl6r0lKylxu/bBuvbas+lS7Nm7ilEkAANAkENh8EIENqJ+2XTop9uorFHf1FYrs2d1aXlLg1NbVn2vLqtVK+T5JxvCfLwAA0DgR2HwQgQ04dV0G9FfsNVfo3PGXK7xDe2t5Xlq6tnz0qbasWq3Mfck2dggAAHDqCGw+iMAGnD4/f3/1HRGn2Kuv0OAxoxTaKsxad2j3Xm3//Eslff6lDu3aY2OXAAAA9UNg80EENqBhBIaEaOCoixV79Tj1v3ikdW83qfrI2/YvvtL2L75U8n+3qaqy0sZOAQAA6kZg80EENqDhtQgP14D4izRo9KXqf9EFCm4Raq0rKXBqx5cbtP2Lr7Tr680qd5fa2CkAAMARBDYfRGADzqyg0BD1u2C4Bo2J18D4ixXWprW1rszl1u6Ezdq+dr12bdyswuwc+xoFAADNHoHNBxHYgLPHPyBAPc4dokGjL9Wgyy5Vuy6dvNYf2r1XuzZu1q6vNyt5y1ZVlJXZ1CkAAGiOCGw+iMAG2Kdjvz4aPCZe51xyoboM7C9/f39rXZnLrX3fbbECXFZyqo2dAgCA5oDA5oMIbIBvCGsdob4XDFfMRSMUc+EIRUR28Fqfdyhdu77erN1ff6N9325RSYHTpk4BAEBTRWDzQQQ2wDdF9+2t/heOUMxFI9QzdqiCQkK81qfv2ad9327Rvu/+q/2J36s4L9+mTgEAQFNBYPNBBDbA9wWFhqj3eecq5sIL1G/kcEX36VVrTMbe/dr33X9raouKcwlwAADg1BDYfBCBDWh8wtq0Vq+4Yep93rnqPTxWnfr1qTUmc3+K9n33X6X8d5tStm5X7oGDNnQKAAAaEwKbDyKwAY1fWOsI9Yz1BLhz1bFfH68JTCSpKDdPP237QSlbtyt1a5IO/PCjylwumzoGAAC+iMDmgwhsQNPTItyhXrFD1eu8c9Vj6GB1GRCjwOBgrzGVFRXK2LNfKVuTlLp1O0fhAABAvbOB/3HX+ICHH35Yxhiv2rlzp7U+JCRECxcuVE5OjoqKivT2228rMjLSaxtdu3bVypUrVVJSoszMTM2dO1cBAQFeY+Lj45WYmCi32609e/ZoypQptXq56667lJycLJfLpU2bNmn48OFn5kMDaFRchUX6Yd0Gffj3BVrwm//VAxdcrmdvuV3vz31W36/+XAUZmQoIDFTnc/rpol9O1M1PPKwHPvqPHl3/if73hWd01b13avDlo9SmU7TdHwUAAPigQLsbOJnt27fr8ssvt55XVFRYj+fPn6+rr75aN954o5xOpxYuXKh33nlHF198sSTJ399fq1atUkZGhi688EJ17NhR//znP1VeXq4HH3xQktSjRw+tWrVKixcv1i233KIxY8ZoyZIlSk9P16effipJmjx5subNm6fp06dr8+bNuu+++7R69WrFxMQoOzv7LH4bAHxdZXm5ftr2g37a9oP0r+plEVEd1H3oYPUYOkjdhw5Sl3NiFNY6QjEXVt9WwKMkv0AHd/yoAzt26eAPO3Vwxy7lp2fY9EkAAIAv8OlTIh9++GH94he/0LnnnltrXXh4uLKzs3XzzTdrxYoVkqSYmBj9+OOPuuCCC7R582aNHz9eK1euVKdOnZSVlSVJmjZtmubMmaMOHTqovLxcTz75pK6++moNHjzY2vby5cvVunVrXXnllZKkTZs26dtvv9Xvfvc7SZKfn58OHDigBQsWaM6cOfX+PJwSCUCSAoKC1LFvL3UZeI66DIhR1wHnqGPf3goIqv1vaMV5+Ur7cbcO7dqrQ7v3KH33XmXtT1XlUf94BQAAGp/6ZgOfP8LWt29fpaWlye12KyEhQbNmzdKBAwcUFxen4OBgrVmzxhq7a9cupaamauTIkdq8ebNGjhyppKQkK6xJ0urVq7V48WINHDhQ33//vUaOHOm1Dc+YZ555RpIUFBSkuLg4PfHEE9Z6Y4zWrFmjkSNHnrD34OBghRx1PyeHw/FzvgoATURlebkO7tilgzt2WcuqQ1xvdfWEuIHnKLpPL7Vq26bWkbiK8nJl7ktW+u59OrRrjw7t3qv03Xu5PxwAAE2QTwe2zZs3a+rUqdq1a5c6duyohx9+WOvXr9egQYMUHR2t0tJSOZ1Or9dkZmYqOrr6WpDo6GhlZmbWWu9Zd6IxERERCg0NVZs2bRQYGFjnmP79+5+w/1mzZumRRx455c8NoPmpDnE/6uCOH61lgcHB6tivjzrF9FGnmL7q1K+POvbroxaOVurcv5869+8n6UprfGF2jtJ371XGvmRl7ktW5r4UZexPlruo2IZPBAAAGoJPB7ZPPvnEepyUlKTNmzcrNTVVkydPlqsRTJH9xBNPaN68edZzh8OhtLQ0GzsC0JhUlJXpwPYdOrB9h9fyNp2iq8NbTYjr1K+P2nXrovAO7RXeob1iLrrAa7wzM1sZ+/ZXB7ian5n7k+Uq5NRsAAB8nU8HtmM5nU7t3r1bffr00WeffaaQkBBFRER4HWWLiopSRkb1RfoZGRk6//zzvbYRFRVlrfP89Cw7eozT6ZTb7VZOTo4qKirqHOPZxvGUlZWprKzs9D4sABxH/qEM5R/K0A/rNljLglu0UHTfXurYp5eievdUdO+eiurdU62joxQR1UERUR28TquUJGdWtrJTflJWyk81P1OVnXJA+YfSVVVZebY/FgAAqEOjCmxhYWHq3bu3/vWvfykxMVFlZWUaM2aM3nnnHUlSv3791L17dyUkJEiSEhIS9OCDD6pDhw7WbI5jx46V0+nUjh07rDFXXXWV1/uMHTvW2kZ5ebkSExM1ZswYvf/++5KqJx0ZM2aMFi5ceFY+NwCcTJnLdWR2yqOEtgpTZK8eiu7dS1G9j/xs0zFaEZEdFBHZQX3Oj/N6TUVZmXIOpCk75Sdlp6RWB7rkn5T90wGV5BecxU8FAAB8epbIp556Sh9++KFSU1PVqVMnzZ49W8OGDdOAAQOUk5OjRYsW6aqrrtLUqVNVWFioBQsWSJIuuugiSdXT+n///fc6dOiQZsyYoejoaP3rX//SkiVLvKb13759u5577jm98sorGj16tP7xj3/o6quv9prW/7XXXtO0adP0zTff6L777tPkyZPVv39/rwlNToZZIgH4ipCwlors2UORPbqpQ89uiuzRXR16dFOHbl0VFBpy3Ne5i0uU89NB5Rw4qJyfDir3QJr1uCg7R8b47P9SAADwKU1ilsguXbpo+fLlateunbKzs7VhwwZdcMEFysnJkST9/ve/V1VVlVasWKGQkBCtXr1ad911l/X6qqoqXXPNNXr++eeVkJCgkpISvfbaa/rLX/5ijUlJSdHVV1+t+fPn695779XBgwd1++23W2FNkt566y116NBBjz76qKKjo/X9999r/PjxpxTWAMCXlJYcrvP6OD8/P7XuGGUFuMieNUGue1e16Rit0FZh6jIgRl0GxNTaZrm7VDkHDir3wEHlpqUr7+Ah5aWlKy/tkPLSDqnM5T5bHw8AgCbDp4+wNTUcYQPQmAUGB6tt545q362r2nfronZdO6t91+qfbTt3VEDgif8NsCg3T3lp6co/VB3irFB3KF0FGVmqKC09S58EAAD71TcbENjOIgIbgKbKPzBAbaKjq0Ncty5q27mT2nbuqLZdOqld505qGRF+0m0U5eYpPz1DBemZyk/PUH56pgrSM6zHXD8HAGhKCGw+iMAGoLkKbRVWE+I6qW2XjmrbqeORUNe5o0JatjzpNspcbhVkZMqZma2CzCw5M7NUkJmlgozqx87MLJUUOE+6HQAAfAGBzQcR2ACgbi3CHWrTMVptOkapTadotY6uedwxWq07RikiskO9tlNeWmoFusKsbDkzs+XMzlFhdk718+wcFWbncvolAMB2BDYfRGADgNMTEBSk1lGRah0dqYjoSLWOilREVKRaR3VQRM3j8Pbt6r29w85CObOyq4Ncdo6cWTkqyslVYU6uimqqMDtXZS7XGfxUAIDmjMDmgwhsAHDmBAQGKjyy/VFhLlLhke0V3qG9wiPbK6JD9X3nTnTbgmOVHj6sopw8rzBXmJOr4tw8Feflq+ion+VujtoBAOqvSUzrDwBAfVVWVCj/UIbyD2WccFyoo5UiOrRXeGQHhXdoX3MD8fZytG8nR7u21T/bt1VoWJhCWrZUSLeWat+ty0nf311SouK8fBXn5qs4L09FufnVz/PyVJxXoJL8AhXn51c/LihQVUVlQ310AEATRmADADQr7qJiuYuKlbk/5YTjglu0kKN9O4W394S4dgqv+elo11at2rZRq3Zt5GjXVkEhIQoNC1NoWJjadz15uJOkw4WFKs7Nrwly1WGuJK9AJU6nSvKdKiko0OGCI4/dxSUN8OkBAI0NgQ0AgDqUuVzVNwE/cPCkY0PCWtaEuLZytGujVu3aytG2+mertm0U1qa1WrVprbA2rRXWOkL+AQFqGR6uluHhUs/u9eqnsryiJswVqKTAqcMFTh12Fuqw0/OzUCUFhTpcWP3Ys76irOznfhUAABsR2AAA+JlKSw6rtOSwcn46ebjz8/dXy3BHdYizwlwbhbWtDnOtakJdy9YRCmvdWmFtIhTSsqUCggIVXnOU71SUudxWiHMVFslVWKjDhUVHPS866nn1OldhkdxFxaqsqDjdrwQA0EAIbAAAnEWmqkolBU6VFDiVlZxar9cEBgfXBLiaqgl1LcId1eEuIlwtI6p/epa3jAhXQGCggluEKrhFqFpHRZ5yr6WHXXIXFetwYaHcRcVyFRXLVVR05KezSO7iYrmKS6z17uLqU05dxSXcPgEAGgCBDQAAH1dRVqbCrGwVZmWf0utCW4UdFeYcahEeXh3mwsPVMtyhFjXVMqL69EzP8xaOVpKkkJYtFNKyhSKi6ncfvFp9l5dXH60rLqkJciVyl9Q8Lq55XLOstLjkyLiS6selJYflLilhghYAzRqBDQCAJspdE4Ly0tJP6XV+/v4KbRVmhbcWjiM/Q8NbVYc7Ryu1CHcotFUrhTrC1KJVK4U6WqlFq1YKaRUmf39/BQYFVc+82a7tz/oc5aWl1QHu8GErxJWWHK4OeTXLrHK5jjw+XPtn2WGXjOGORgAaDwIbAADwYqqqrOvbToefn5+CW7aoDniOVmrRKkyhDodCW1XPpBnaqqVCWlWHvJCwsCPLHdU/Q2qeB7cIlSQFhYQoKCTkZwc/j9LDLpW5XFaAKz3sUtnhwyr1PK5Z53lc5vnpch+13rOsen25u5QgCOCMILABAIAGZYyxjnIpI/O0t+MfEKCQsJYKadlSoa3CFBLWsjrQHfXTE+5CWraoGdtCIS1r1lnPqx/7BwRIOnKqZ0MFQA9PiCt3l1YHObdbZS639zLX0cvcKnOXqtzltsZWLzv6canK3W6Vu0uZ8RNopghsAADAJ1VVVv6sI33HCgwJUWhYSwXXBLaQFi0V3DJUwS2qg12wJ9x5Hoe1VEiLFtUTt7RsqeAWoQqp+RncooWCW1Rvx8MTBM+UqqoqK7yVud2qKC2rDnalpVbQK3eX1jyv+el57K5jmfWzelvV66p/VpSWERABH0FgAwAAzUJFaamKS0ulvPwG26afn5+CQkMU3LKFgkM9QS5UQTWPQ1qEKqjFkeWeMUGhIUfGhYZWPw8NVXDLFtbj6m2EKiCw+tc1f3//mkDZssH6P5GqqioruJW7S1VeVmoFu4rSMpWXlR15ftTj8prXWMvKylRRWlr9s6y8ZpueceWqKCut+Vk9vqK85nFZuUxV1Vn5rIAvI7ABAACcJmOMdZrjmRIQGKig0Orr+IJahCooJMQKedWBL+Sox6FHxoaEHHkcGqLAo557xgUGB1cvCw621vv7+0uqDoie20Io4ox9vBOqLK9QRXlNkCsrr35cdiTQWcGw5nFlebn3+prxRy+3tllrebkqyo9adtTjyvLy6teVlXF/Qpx1BDYAAAAfVllRocriCrmLS87K+3kCYmBI8JHgF1L9PDA4WEEhwQoMDjkq6FVXUPCR1wQGB3ktCwwOskLhkW3UlLU+RAHBQVZglKSAoEAFBAWetaOK9eUJc9Xhr+7HRwLgkcdVFRWqqHleWXHU+IoKa1xleYUqK8pVWV551Lry6tdVVHiPr6hQVUXN8opj11ceWVdezqQ4jRiBDQAAABZPQNRZCojHCggMrAlz1aEvMKh2qLPWBwcrICiweszRy4OCFHCcMQFBQUfGBh15bi33LKv5GRAUaJ2W6hFYs74xqaqstEJdVUXlUQHvqNBXfiT4eY0vr1Bl5ZEAWFVZWWts9bojP2tt45hlVRWVRx57LTt6m5Xejysra73eU00ZgQ0AAAA+w/MLfulhuzs5ws/fvybEBVoB8EioC1RA4FGPrcBXMyY4WAGBAdbygMDAmgDp/dyzPf/AgJqfNWM8rw0MrDU+ILA6TB79Gs+2j+UfECD/gAAFhYTY8A2eeVawOzboVVZWB8mjwl3ylq1a8ben7G653ghsAAAAwAmYqipVlJaqorRUkj1HHk+Vf2CAFei8w11gTQg8+nngMesDvV8fGHCc5YHyD6h+7h8UqICAmnGenzWv84zxvN56TUCAtT3/gIBarwuoCZme13heVxfP9uuj4GfcbsQOBDYAAACgiamqqD7SVK5Su1tpUH5+fvIL8Jd/gCcYHhX+jgp3AV5Br2ZsTag8XFho98c4JQQ2AAAAAI2CMUamJow2l/k6/U8+BAAAAABgBwIbAAAAAPgoAhsAAAAA+CgCGwAAAAD4KAIbAAAAAPgoAhsAAAAA+CgCGwAAAAD4KAIbAAAAAPgoAhsAAAAA+CgCGwAAAAD4KAIbAAAAAPgoAhsAAAAA+CgCGwAAAAD4KAIbAAAAAPgoAhsAAAAA+CgCGwAAAAD4KAIbAAAAAPgoAhsAAAAA+CgCGwAAAAD4KAIbAAAAAPgoAhsAAAAA+KhAuxtojhwOh90tAAAAALBRfTMBge0s8uyUtLQ0mzsBAAAA4AscDoeKioqOu95Pkjl77aBTp04n3CFni8PhUFpamjp37uwT/eDUsP8aN/Zf48b+a7zYd40b+69xY//VzeFw6NChQyccwxG2s+xkO+RsKyoq4i9NI8b+a9zYf40b+6/xYt81buy/xo39560+3wWTjgAAAACAjyKwAQAAAICPIrA1U6WlpXrkkUdUWlpqdys4Dey/xo3917ix/xov9l3jxv5r3Nh/p49JRwAAAADAR3GEDQAAAAB8FIENAAAAAHwUgQ0AAAAAfBSBDQAAAAB8FIGtmbrrrruUnJwsl8ulTZs2afjw4Xa3hDpccskl+uCDD5SWliZjjK677rpaY2bPnq1Dhw7p8OHD+uyzz9SnTx8bOsWx7r//fn3zzTcqLCxUZmam3n33XfXr189rTEhIiBYuXKicnBwVFRXp7bffVmRkpE0d42jTp0/X1q1b5XQ65XQ69fXXX2v8+PHWevZd4zFz5kwZYzR//nxrGfvPtz388MMyxnjVzp07rfXsP9/WqVMn/etf/1JOTo4OHz6sbdu2KS4uzmsMv7ucOkM1r5o8ebJxu91m6tSp5pxzzjEvvPCCycvLMx06dLC9N8q7xo8fb/7617+aX/ziF8YYY6677jqv9TNmzDD5+fnm2muvNYMHDzbvvfee2bdvnwkJCbG99+ZeH3/8sZkyZYoZMGCAGTJkiFm5cqVJSUkxLVu2tMYsWrTIpKammssuu8zExsaar7/+2mzYsMH23imZa665xlx55ZWmT58+pm/fvuZvf/ubKS0tNQMGDGDfNaI677zzzP79+833339v5s+fby1n//l2PfzwwyYpKclERUVZ1a5dO/ZfI6jWrVub5ORk88orr5jhw4ebHj16mLFjx5pevXpZY/jd5bTK9gaos1ybNm0yCxYssJ77+fmZgwcPmpkzZ9reG3X8qiuwHTp0yPzxj3+0noeHhxuXy2Vuuukm2/ulvKt9+/bGGGMuueQSa1+VlpaaiRMnWmNiYmKMMcaMGDHC9n6p2pWbm2tuu+029l0jqbCwMLNr1y4zZswYs3btWiuwsf98vx5++GHz3//+t8517D/frieeeMJ89dVXJxzD7y6nXpwS2cwEBQUpLi5Oa9assZYZY7RmzRqNHDnSxs5wqnr27KmOHTt67cvCwkJt3ryZfemDIiIiJEl5eXmSpLi4OAUHB3vtv127dik1NZX952P8/f110003KSwsTAkJCey7RuK5557TqlWr9Pnnn3stZ/81Dn379lVaWpr27dun119/XV27dpXE/vN11157rb777ju99dZbyszM1JYtW3T77bdb6/nd5fQQ2JqZ9u3bKzAwUJmZmV7LMzMzFR0dbVNXOB2e/cW+9H1+fn565plntGHDBv3www+SqvdfaWmpnE6n11j2n+8YNGiQioqKVFpaqsWLF+v666/Xzp072XeNwE033aTY2FjNmjWr1jr2n+/bvHmzpk6dqvHjx+vOO+9Uz549tX79erVq1Yr95+N69eqlO++8U3v27NEVV1yh559/Xv/4xz906623SuJ3l9MVaHcDANDUPffccxo0aJAuvvhiu1vBKdi1a5eGDRumiIgITZo0Sa+99pri4+Ptbgsn0aVLFz377LMaO3asSktL7W4Hp+GTTz6xHiclJWnz5s1KTU3V5MmT5XK5bOwMJ+Pv76/vvvtODz74oCTp+++/16BBgzR9+nT985//tLm7xosjbM1MTk6OKioqFBUV5bU8KipKGRkZNnWF0+HZX+xL37ZgwQJdc801uuyyy5SWlmYtz8jIUEhIiHWqpAf7z3eUl5dr37592rJlix544AFt3bpV9957L/vOx8XFxSkqKkpbtmxReXm5ysvLNWrUKN1zzz0qLy9XZmYm+6+RcTqd2r17t/r06cPfPx+Xnp6uHTt2eC3buXOnunXrJonfXU4Xga2ZKS8vV2JiosaMGWMt8/Pz05gxY5SQkGBjZzhVycnJSk9P99qXDodDI0aMYF/6iAULFuj666/X6NGjlZKS4rUuMTFRZWVlXvuvX79+6t69O/vPR/n7+yskJIR95+M+//xzDRo0SMOGDbPq22+/1bJlyzRs2DB999137L9GJiwsTL1791Z6ejp//3zcxo0bFRMT47WsX79+Sk1NlcTvLj+H7TOfUGe3Jk+ebFwul7n11ltN//79zeLFi01eXp6JjIy0vTfKu8LCwszQoUPN0KFDjTHG3HfffWbo0KGma9euRqqeGjcvL89MmDDBDBo0yLz77rtMjesj9dxzz5n8/Hxz6aWXek1NHRoaao1ZtGiRSUlJMaNGjTKxsbFm48aNZuPGjbb3Tsk8/vjj5pJLLjHdu3c3gwYNMo8//riprKw0l19+OfuuEdbRs0Sy/3y/nnrqKXPppZea7t27m5EjR5pPP/3UZGVlmfbt27P/fLzOO+88U1ZWZmbNmmV69+5tfvWrX5ni4mJz8803W2P43eW0yvYGKBvq7rvvNikpKcbtdptNmzaZ888/3/aeqNoVHx9v6rJ06VJrzOzZs016erpxuVzms88+M3379rW9b0p17jdjjJkyZYo1JiQkxCxcuNDk5uaa4uJis2LFChMVFWV775TMkiVLTHJysnG73SYzM9N89tlnVlhj3zW+Ojawsf98u5YvX27S0tKM2+02Bw4cMMuXL/e6jxf7z7fr6quvNtu2bTMul8vs2LHD3H777bXG8LvLqZVfzQMAAAAAgI/hGjYAAAAA8FEENgAAAADwUQQ2AAAAAPBRBDYAAAAA8FEENgAAAADwUQQ2AAAAAPBRBDYAAAAA8FEENgAAAADwUQQ2AAB8UHx8vIwxioiIsLsVAICNCGwAAAAA4KMIbAAAAADgowhsAADUwc/PT/fff7/279+vw4cP6/vvv9fEiRMlHTld8aqrrtLWrVvlcrmUkJCggQMHem3jhhtu0Pbt2+V2u5WcnKw//OEPXuuDg4P15JNP6qeffpLb7daePXt02223eY2Ji4vTt99+q5KSEm3cuFH9+vWz1g0ZMkRffPGFCgsL5XQ69d133ykuLu4MfSMAALsYiqIoiqK864EHHjA7duww48aNMz179jRTpkwxLpfLXHrppSY+Pt4YY8wPP/xgLr/8cjNo0CDzwQcfmP3795vAwEAjycTGxpqKigrz0EMPmb59+5opU6aYkpISM2XKFOs93nzzTZOammp+8YtfmJ49e5rRo0ebyZMnG0nWeyQkJJhLL73UnHPOOebLL780GzZssF6flJRk/vnPf5qYmBjTp08fM2nSJDNkyBDbvzuKoiiqQcv2BiiKoijKpyo4ONgUFxebCy64wGv5Sy+9ZJYtW2aFKU+4kmTatGljSkpKzI033mgkmddff92sXr3a6/Vz5swx27dvN5JM3759jTHGjBkzps4ePO8xevRoa9mVV15pjDEmJCTESDJOp9Pceuuttn9fFEVR1JkrTokEAOAYffr0UVhYmD777DMVFRVZdeutt6p3797WuISEBOtxfn6+du3apXPOOUeSdM4552jjxo1e2924caP69u0rf39/DRs2TBUVFfryyy9P2Mu2bdusx+np6ZKkyMhISdK8efO0ZMkSffbZZ5o5c6Z69er18z44AMDnENgAADhGq1atJElXX321hg0bZtWAAQM0adKkBnkPl8tVr3Hl5eXWY2OMJMnfv/p/37Nnz9bAgQO1atUqjR49Wjt27NAvfvGLBukPAOAbCGwAgP/fzh27pBbGYRx/rlypTaemyK0tnITiEI4Obv4Ftka4uEabU0rhHyC4CFKGm6tDg9AURgcUsQM2CDkkDselX8vFi3e5F+LiS3w/8MCB856Xl7M9nPO++MPz87PCMNTe3p5Go9FaJpPJatzh4eHqOh6Pa39/X77vS5J835fneWvzep6nwWCgj48P9ft9RSIRpdPpL611OBzq+vpamUxGd3d3Ojk5+dJ8AAC3/Nz0AgAAcM1isVC5XNbV1ZUikYju7+8Vi8XkeZ7m87mCIJAkXVxcaDabaTqdqlQq6e3tTe12W5JUqVT08PCg8/NzNZtNHR0d6ezsTKenp5KkIAhUr9dVq9VUKBT0+PioRCKhnZ0d3dzc/HWN29vbury81O3trcbjsXZ3d5VKpdRqtf7bewEAbMbGN9IRQgghLqZQKJjv+7ZcLm06nVqn07Hj4+PVgSDZbNb6/b6FYWi9Xs8ODg7Wns/lcvb09GTL5dJeXl6sWCyu3d/a2rJKpWKvr68WhqENBgPL5/Mm/T50JBaLrcYnk0kzM0skEhaNRq3RaFgQBBaGoU0mE6tWq6sDSQghhHyP/Ph1AQAA/lE6nVa321U8Htf7+/umlwMA+MbYwwYAAAAAjqKwAQAAAICj+CUSAAAAABzFFzYAAAAAcBSFDQAAAAAcRWEDAAAAAEdR2AAAAADAURQ2AAAAAHAUhQ0AAAAAHEVhAwAAAABHUdgAAAAAwFGfrmwNSm6re/MAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd9PcTFwkFwo"
      },
      "source": [
        "# 3. Introducing regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWkYPM1dkF1u"
      },
      "source": [
        "Let us introduce a regularization penalty term in the cost function. The new cost function is defined as follows:\n",
        "\n",
        "\n",
        "\\begin{equation*}\n",
        "\\tilde{J} = \\sum\\limits_{i=1}^V \\sum\\limits_{j=1}^V f(X_{ij}) (\\log X_{ij} - W_i^T \\tilde{W}_j - b_i - \\tilde{b}_j)^2 + \\lambda \\left( ||W||_{\\text{F}}^2 +   ||\\tilde{W}||_{\\text{F}}^2 + ||b||_2^2 + ||\\tilde{b} ||_2^2 \\right)\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q16:</font>\n",
        "<br><font color='green'>\n",
        "Show that:\n",
        "\\begin{equation}\n",
        "||W||_{\\text{F}}^2 = \\sum\\limits_{i=1}^V W_i^T W_i\n",
        "\\end{equation}\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0Fgcb-ASEAad"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QT6sJx8wTDaE"
      },
      "source": [
        "---\n",
        "**Solution:**\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q17:</font>\n",
        "<br><font color='green'>\n",
        "Deduce that for all $i \\in \\{1, \\dots, V \\}$:\n",
        "\\begin{align}\n",
        "& \\nabla_{W_i} (||W||_{\\text{F}}^2) = 2W_i \\quad \\text{(3.1)} \\\\\n",
        "&(\\text{Hint}: \\forall z \\in \\mathbb{R}^D \\ \\forall A \\in \\mathcal{M}_{D, D}(\\mathbb{R}) \\quad \\nabla_z (z^T A z) = (A + A^T)z )\n",
        "\\end{align}\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JgdEJEcFEBCh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Wcp4if-VP9y"
      },
      "source": [
        "---\n",
        "**Solution:**\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q18:</font>\n",
        "<br><font color='green'>\n",
        "From the equations(2.1), (2.2), (2.3), (2.4) and (3.1), show that the update equations for the method of alternating least squares become:\n",
        "\n",
        "\\begin{align*}\n",
        "&W_i^{(t+1)} \\longleftarrow \\left( \\sum_{j'=1}^V f(X_{ij'}) \\tilde{W}_{j'}^{(t)} \\tilde{W}_{j'}^{(t)^T} + \\lambda I_D \\right)^{-1} \\left( \\sum_{j'=1}^{V} f(X_{ij'})( \\log X_{ij'} - b_i^{(t)} - \\tilde{b}_{j'}^{(t)}) \\tilde{W}_{j'}^{(t)} \\right)  \\\\\n",
        "&\\tilde{W}_j^{(t+1)} \\longleftarrow \\left( \\sum_{i'=1}^V f(X_{i' j}) W_{i'}^{(t)} W_{i'}^{(t)^T} + \\lambda I_D \\right)^{-1} \\left( \\sum_{i'=1}^{V} f(X_{i' j})( \\log X_{i' j} - b_{i'}^{(t)} - \\tilde{b}_{j}^{(t)}) W_{i'}^{(t)} \\right) \\\\\n",
        "&b_i^{(t+1)} \\longleftarrow \\left( \\sum_{j'=1}^V f(X_{ij'}) + \\lambda  \\right)^{-1} \\left( \\sum_{j'=1}^{V} f(X_{ij'})( \\log X_{ij'} - W_i^{(t)^T} \\tilde{W}_{j'}^{(t)} - \\tilde{b}_{j'}^{(t)}) \\right)  \\\\\n",
        "&\\tilde{b}_j^{(t+1)} \\longleftarrow \\left( \\sum_{i'=1}^V f(X_{i' j}) + \\lambda  \\right)^{-1} \\left( \\sum_{i'=1}^{V} f(X_{i' j})( \\log X_{i' j} - W_{i'}^{(t)^T} \\tilde{W}_{j}^{(t)} - b_{i'}^{(t)}) \\right)\n",
        "\\end{align*}\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HcfbBXP2EBpp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTCLv_fKcEej"
      },
      "source": [
        "---\n",
        "**Solution:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<font color=green>Q19:</font>\n",
        "<br><font color='green'>\n",
        " What would be the update equations for minimizing the new loss function $\\tilde{J}$ by using the gradient descent algorithm.\n",
        "</font>\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "OcsjfGD9EC2C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-7Z2AL-hU2w"
      },
      "source": [
        "---\n",
        "**Solution:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_I-tM9dK3dY"
      },
      "source": [
        "\n"
      ]
    }
  ]
}